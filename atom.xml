<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://mzhtech.github.io</id>
    <title>今天学习了没</title>
    <updated>2024-11-15T07:27:15.444Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://mzhtech.github.io"/>
    <link rel="self" href="https://mzhtech.github.io/atom.xml"/>
    <subtitle>希望每天都有收获</subtitle>
    <logo>https://mzhtech.github.io/images/avatar.png</logo>
    <icon>https://mzhtech.github.io/favicon.ico</icon>
    <rights>All rights reserved 2024, 今天学习了没</rights>
    <entry>
        <title type="html"><![CDATA[服务稳定性建设方法论]]></title>
        <id>https://mzhtech.github.io/post/fu-wu-wen-ding-xing-jian-she-fang-fa-lun/</id>
        <link href="https://mzhtech.github.io/post/fu-wu-wen-ding-xing-jian-she-fang-fa-lun/">
        </link>
        <updated>2024-11-15T07:14:53.000Z</updated>
        <content type="html"><![CDATA[<h1 id="提升系统稳定性的方法">提升系统稳定性的方法</h1>
<p>本文主要从三个方面介绍提升系统稳定性的方法：故障预防、故障发现和故障恢复，主要包括以下内容：<br>
<img src="https://mzhtech.github.io/post-images/1731654965243.png" alt="" loading="lazy"></p>
<h2 id="基础概念">基础概念</h2>
<h3 id="sla-slo-sli">SLA, SLO, SLI</h3>
<h4 id="sli">SLI</h4>
<p><strong>服务等级指标 (Service Level Indicator)</strong><br>
提供服务的指标，SLI 由每个部门自定义，没有统一的划分。<br>
指标包括：测量指标的定义及具体计算方式、具体测量范围及方式<br>
指标包括：</p>
<ul>
<li><strong>性能</strong>：响应时间、吞吐量、请求量</li>
<li><strong>可用性</strong>：运行时间、故障时间/频率、响应时间、修复时间、修复率</li>
<li><strong>可靠性</strong>：正确性、完整性</li>
</ul>
<h4 id="slo">SLO</h4>
<p><strong>服务等级目标 (Service Level Objectives)</strong><br>
服务所提供功能的一种期望状态。<br>
SLO描述服务应该提供什么样功能。没有提到，如果目标达不到会怎样。<br>
SLO 是用 SLI 来描述的，例如：</p>
<ul>
<li>每分钟平均 QPS &gt; 100k/s</li>
<li>99% 访问延迟 &lt; 500ms</li>
</ul>
<h4 id="sla">SLA</h4>
<p><strong>服务等级协议 (Service Level Agreement)</strong><br>
SLA是一个涉及双方的合约，双方必须都要同意并遵守这个合约。<br>
SLA用一个简单的公式来描述就是： SLA = SLO 后果。比如：达到响应时间SLO、未达到可用性SLO<br>
对动作的具体实施，需要奖励/惩罚，比如：钱<br>
例如：达到响应时间 SLO、未达到可用性 SLO。</p>
<h3 id="年可用性计算">年可用性计算</h3>
<p>1年 = 365天 = 8760小时</p>
<ul>
<li><strong>99.9%</strong> 可用性：
<ul>
<li><code>8760 * 0.1% = 8.76小时</code></li>
</ul>
</li>
<li><strong>99.99%</strong> 可用性：
<ul>
<li><code>8760 * 0.0001 = 0.876小时 = 52.6分钟</code></li>
</ul>
</li>
<li><strong>99.999%</strong> 可用性：
<ul>
<li><code>8760 * 0.00001 = 0.0876小时 = 5.26分钟</code></li>
</ul>
</li>
</ul>
<h3 id="强弱依赖">强弱依赖</h3>
<ul>
<li><strong>强依赖</strong>：影响核心业务流程、系统可用性的依赖。</li>
<li><strong>弱依赖</strong>：不影响核心业务流程、系统可用性的依赖。</li>
</ul>
<h3 id="并发数-吞吐量-响应时间">并发数、吞吐量、响应时间</h3>
<ul>
<li><strong>并发数</strong>：同一时刻处理的请求数，受限于 worker 数量、CPU、内存等。</li>
<li><strong>响应时间</strong>：处理一个请求的响应时间。
<ul>
<li><code>avg</code>：平均响应时间</li>
<li><code>pct99</code>：99%的请求响应时间</li>
</ul>
</li>
<li><strong>吞吐量 (QPS)</strong>：每秒钟处理的请求数。</li>
</ul>
<h3 id="cpu-使用率-内存和-load">CPU 使用率、内存和 Load</h3>
<ul>
<li><strong>Load</strong>：负载平均，表示在过去1分钟、5分钟和15分钟内运行队列的平均长度。</li>
<li><strong>CPU 使用率</strong>：表示 CPU 正在执行指令的时间比例。</li>
<li><strong>内存使用率</strong>：系统中内存的使用情况。</li>
</ul>
<h4 id="load-与-cpu-使用率的关系">Load 与 CPU 使用率的关系</h4>
<ul>
<li>CPU 利用率关注的是 CPU 的忙碌程度，而负载关注的是系统中等待运行的工作量。</li>
<li>高 CPU 利用率表示 CPU 正在积极工作，而低 CPU 利用率可能意味着 CPU 大部分时间处于空闲。</li>
<li>高负载意味着有很多进程等待使用 CPU，可能导致系统响应变慢。</li>
</ul>
<h2 id="治理思路">治理思路</h2>
<p>稳定性是一种面向风险设计，使系统具备控制风险、提供更高可用性的能力。<br>
如果我们把风险记为 <code>r</code>，那么风险变成故障的概率则记为 <code>P(r)</code>。<br>
故障影响面 = 故障影响范围 × 故障持续时间。<br>
想要提升稳定性，需要从四个方面入手：</p>
<ul>
<li>减少风险的数量</li>
<li>降低风险变故障的概率</li>
<li>控制故障影响范围</li>
<li>缩短故障影响时长<br>
⾼可⽤问题的特点和⽊桶理论相似。 如果我们把链路看成⼀个桶， 把可⽤性看做桶的容量， 那么链路上的强依赖就是就是组成这个桶的⽊板，⼀张⽊板是短板， 就会降低整个桶的容量（可⽤性）。</li>
</ul>
<h2 id="治理方法">治理方法</h2>
<h3 id="故障预防">故障预防</h3>
<h4 id="链路梳理">链路梳理</h4>
<p>链路梳理是发现风险的有效手段之一。常见的梳理方式有：</p>
<ul>
<li>
<p><strong>工具梳理</strong>：</p>
<ul>
<li>自动采集，人工打标识别风险。</li>
<li>优点：成本低；缺点：精度低，不直观。</li>
</ul>
</li>
<li>
<p><strong>人工梳理</strong>：</p>
<ul>
<li>人工梳理链路，识别风险。</li>
<li>优点：精准直观，方便理解业务流程，快速发现风险；缺点：成本高。</li>
</ul>
</li>
</ul>
<p>实际中可以结合两种方式：先通过工具梳理链路，然后人工打标链路中的核心依赖。</p>
<h4 id="依赖治理">依赖治理</h4>
<ul>
<li><strong>依赖是否合理</strong>：能否去掉这个依赖，或者多个依赖合并。</li>
<li><strong>依赖强弱是否合理</strong>：结合业务特性评估。</li>
<li><strong>依赖能否降级</strong>：
<ul>
<li><strong>弱依赖</strong>：兜底&amp;容错、重试&amp;补偿、预案降级能力。</li>
<li><strong>强依赖</strong>：合理性分析、降级可行性分析。</li>
</ul>
</li>
</ul>
<h3 id="降级">降级</h3>
<p>服务降级是在系统负载过高或某些服务无法使用时，临时关闭部分功能或降低服务标准的策略，以保障核心业务正常运作。</p>
<h4 id="降级的方式">降级的方式</h4>
<ul>
<li><strong>延迟服务</strong>：例如，发表评论但延迟给用户增加积分，先将其放入缓存。</li>
<li><strong>关闭服务</strong>：在粒度范围内关闭服务，例如双十一期间无法退款。</li>
<li><strong>页面异步请求降级</strong>：如页面上有异步请求，响应慢时可跳转到降级页面。</li>
<li><strong>写降级</strong>：如秒杀抢购，仅更新缓存，然后异步同步扣减库存到数据库。</li>
<li><strong>读降级</strong>：如多级缓存模式，后端服务有问题时可降级为只读缓存。</li>
</ul>
<h3 id="降级的介入">降级的介入</h3>
<h4 id="自动开关降级">自动开关降级</h4>
<p>系统满足某些设定条件时，自动执行某些策略。常见的可作为自动降级条件的指标包括：</p>
<ul>
<li>
<p><strong>服务超时</strong><br>
当访问的服务响应缓慢且并非核心服务时，可在超时时自动降级。</p>
</li>
<li>
<p><strong>失败次数</strong><br>
例如，详情页中的库存信息，若某次查询请求失败，可以通过读取缓存数据等方式直接降级。<br>
<strong>问题</strong>：虽然一次请求展示了缓存，但其他用户访问时仍会查询库存信息，可能已出现问题，上游系统仍不断发送请求。<br>
<strong>解法</strong>：设定一个失败次数的阈值，一旦失败次数达到阈值，就对该查询接口进行降级，直至功能恢复。</p>
</li>
<li>
<p><strong>发生故障</strong><br>
依赖的服务完全瘫痪，或网络不通等情况可直接降级。</p>
</li>
<li>
<p><strong>限流降级</strong><br>
设定一个流量阈值，一旦流量达到阈值，就进行降级。例如，秒杀功能若瞬间流量过大，对于后续访问的用户直接提示已售空、跳转错误页，或让其输入验证码重试等。</p>
</li>
</ul>
<h4 id="人工开关降级">人工开关降级</h4>
<p>系统异常后，通过人工关闭服务等方式进行降级。</p>
<ul>
<li><strong>优点</strong>：比较灵活，能够依据异常情况灵活处理。</li>
<li><strong>缺点</strong>：对人的要求较高，需要对系统有充分的了解，在系统异常时能够立刻进行处理。</li>
</ul>
<h3 id="超时配置">超时配置</h3>
<p>所有下游依赖，包括中间件，使用时都严禁不主动配置超时时间，直接使用默认值。超时时间的配置思路如下：</p>
<ol>
<li><strong>整体接口对外承诺时间</strong>：拆解到这个模块有多少时间。</li>
<li><strong>查服务和写服务</strong>：
<ul>
<li><strong>写服务</strong>：更应该关注返回结果，可以配置大一点，平时表现的1.5-2倍。</li>
<li><strong>查服务</strong>：天然幂等，可以快速失败重试，超时时间稍微短一点，以预留出重试的时间。</li>
</ul>
</li>
</ol>
<h3 id="重试">重试</h3>
<p>在分布式系统中，为了保证整体服务可用性和一致性，很多系统都会引入重试机制。</p>
<ul>
<li>
<p><strong>优点</strong>：</p>
<ul>
<li>针对网络抖动或下游单实例故障的场景，重试效果很好。</li>
</ul>
</li>
<li>
<p><strong>缺点</strong>：</p>
<ul>
<li>下游系统因为请求量太大，导致 CPU 被打满，数据库连接池被占满。此时，上游系统的重试请求无疑是雪上加霜，给下游系统造成二次伤害。</li>
<li>重试如果在调用链的每层都加上，若有小的抖动，就容易造成重试次数放大，进而引起雪崩。</li>
</ul>
</li>
</ul>
<p>因此，业务方需要结合实际场景，进行合理的重试和控制：</p>
<ul>
<li>有开关可以控制打开重试以及控制重试次数。</li>
<li>请求失败超过一定次数可以开启熔断。</li>
<li>加重试时需要和下游进行确认，确保其能承受并且是幂等的。</li>
</ul>
<h3 id="熔断">熔断</h3>
<p><strong>服务雪崩</strong>：某个服务响应时间过长或完全没有响应，重复请求这个服务，将整个分布式系统拖垮。大多数服务雪崩都是由不断重试所导致的，这种重试可能是框架重试、代码重试或用户主动重试。</p>
<p>在服务的依赖调用中，当被调用方出现故障时，出于自我保护的目的，调用方会主动停止调用，并根据业务需要进行相应处理。调用方这种主动停止调用的行为称为<strong>熔断</strong>。</p>
<h3 id="隔离建设">隔离建设</h3>
<h4 id="隔离方式">隔离方式</h4>
<ol>
<li>
<p><strong>业务能力隔离</strong></p>
<ul>
<li><strong>读写应用拆分/CQRS</strong>：将同一块业务拆分为读和写两个应用。写操作偏向 B 端，读操作偏向 C 端，因而对两者的稳定性要求也不相同。</li>
</ul>
</li>
<li>
<p><strong>集群能力隔离</strong></p>
<ul>
<li>当业务流量和核对流量都调用同一个服务时，要求保证 CPU 保持在一定的水位。改造后，业务流量继续使用原集群，而 BCP 核对则调用 BCP 集群。业务分组按照高保要求保障，核对分组 CPU 水位可以放开到更高，从而提升稳定性的同时降低了成本。</li>
</ul>
</li>
<li>
<p><strong>数据库读写分离</strong></p>
<ul>
<li>将数据库的读操作和写操作分开，通常通过主从复制的方式实现。主数据库处理写请求，从数据库处理读请求，从而减轻主数据库的压力，提高整体系统的性能和可用性。</li>
</ul>
</li>
</ol>
<h3 id="限流治理">限流治理</h3>
<p>限流要考虑两个方面：</p>
<ul>
<li><strong>入口限流</strong>：保护自己，防止突发流量击垮。</li>
<li><strong>出口限流</strong>：保护下游，防止自己击垮下游服务。</li>
<li></li>
</ul>
<h3 id="限流后的策略">限流后的策略</h3>
<p>不管是为了保护自己还是保护下游，限流之后可以采取以下策略：</p>
<ol>
<li>
<p><strong>直接抛错</strong></p>
<ul>
<li>这种方式的用户体验不够友好，但可以搭配重试策略使用。用户在遭遇错误时，可以通过重试机制尝试再次发送请求。</li>
</ul>
</li>
<li>
<p><strong>削峰，排队</strong></p>
<ul>
<li>这种方式相对友好，先受理请求再进行缓慢处理。以下是具体场景的示例：
<ul>
<li><strong>实时修改活动的使用门店</strong>：商家在修改活动时，调用实时修改接口。对于大型连锁店商家，一次修改可能涉及大量门店分组数据的 CRUD 操作。如果短时间内有多次这样的操作，会对数据库产生巨大的压力。在这种情况下，可以先受理请求，再进行处理。虽然会影响用户的使用方式（之前是同步反馈修改操作结果），但改造后可以改为异步通知用户修改结果。</li>
<li><strong>合并更新请求</strong>：如果有 10 条增加积分的操作要执行，可以先计算出这十条操作一共要加多少积分，然后一次性加上去。通过批量执行的方式来降低请求量，减少对系统的压力。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>常见的限流算法：</p>
<ul>
<li><strong>漏桶</strong>：通过固定容量的漏桶控制请求处理速率。</li>
<li><strong>令牌桶</strong>：通过定时器向桶中添加令牌，处理突发流量。</li>
<li><strong>计数器</strong>：通过比较当前请求数与限流阈值判断是否限流。</li>
<li><strong>滑动窗口限流</strong>：基于固定大小的时间窗口，允许在该时间窗口内的请求数不超过设定的阈值。</li>
<li><strong>自适应限流</strong>：限流器结合服务器的Load、CPU、内存、接口的RT、QPS、并发线程数等指标，进行的一种自适应的流控策略。通过监控这些指标的变化，来动态的调整限流，来达到保证系统稳定性的目的。</li>
</ul>
<h3 id="单机限流与集群限流">单机限流与集群限流</h3>
<h4 id="限流方式">限流方式</h4>
<ol>
<li>
<p><strong>单机限流</strong></p>
<ul>
<li>针对单台服务器进行流量控制。即使集群级别有流量控制，单个实例依然可能因为本地请求过多而出现性能问题或崩溃。</li>
</ul>
</li>
<li>
<p><strong>集群限流</strong></p>
<ul>
<li>针对整个集群进行流量控制。整个服务集群可能面临全局的流量波动和峰值，因此需要集群级别的流量控制策略来确保整体系统的稳定性和可靠性。</li>
</ul>
</li>
</ol>
<h4 id="必要性">必要性</h4>
<ul>
<li>单机限流可以防止单台服务器因过载而崩溃，确保其性能稳定。</li>
<li>集群限流能够应对全局流量波动，确保多个实例之间的负载均衡，提高系统的可靠性。</li>
</ul>
<h3 id="压测">压测</h3>
<p>压测通过模拟用户请求，帮助发现系统瓶颈以及评估系统的整体水位。以下是进行压测的一般步骤：</p>
<ol>
<li><strong>确定测试目标</strong></li>
<li><strong>制定压测计划</strong></li>
<li><strong>创建环境并准备脚本</strong>：压测的环境需要和线上环境尽量保持一致。</li>
<li><strong>执行压测</strong></li>
<li><strong>监控系统性能</strong>：包括但不限于 RT、CPU 利用率、Load、内存情况、GC 次数、GC 时长、网络 IO 情况、堆内存情况、线上报警情况等。</li>
<li><strong>分析结果</strong></li>
<li><strong>优化和再测试</strong></li>
</ol>
<h3 id="全链路压测">全链路压测</h3>
<p>单链路压测通常只关注自己的系统，可能忽略一些资源竞争及外部干扰，最终得到一个过于乐观的结果。在分布式场景中，只有在全链路压测中才能真正暴露出真实环境中的各种问题。</p>
<ul>
<li><strong>全链路压测</strong>可以从网络到 Nginx 反向代理、应用服务器、系统间依赖、数据库、缓存、磁盘等全方位找出系统瓶颈。</li>
<li>需要能识别出压测流量，尤其是写操作产生的数据，需要做好数据隔离（如影子库、影子表）。</li>
</ul>
<h3 id="容灾">容灾</h3>
<ul>
<li><strong>同城容灾与异地容灾</strong>：容灾切流时支持同城和异地方式。</li>
</ul>
<h3 id="多活">多活</h3>
<ol>
<li>
<p><strong>异地多活</strong></p>
<ul>
<li>让多个数据中心在不同地理位置提供相同的服务。</li>
</ul>
</li>
<li>
<p><strong>同城多活</strong></p>
<ul>
<li>在同一城市或地理区域内提供高可用性和容灾能力。</li>
</ul>
</li>
</ol>
<p>在异地多活和同城多活的架构中，每个数据中心均具备完整的应用程序及数据副本，能够同时提供服务并处理客户端请求。若一个数据中心出现故障，能够借助自动切换和故障转移机制将流量转移至其他正常的数据中心，以保障系统的可用性与可靠性。</p>
<h3 id="故障演练">故障演练</h3>
<ul>
<li><strong>线上故障演练</strong>：例如代码注入报错。</li>
<li><strong>机房故障演练</strong>：模拟机房故障情景，测试应急响应能力。</li>
</ul>
<h3 id="故障发现">故障发现</h3>
<h4 id="大盘建设">大盘建设</h4>
<p>线上出现问题时，大盘可以快速定位到问题方。建设大盘需要考虑以下三个因素：</p>
<ul>
<li><strong>范围</strong>：核心业务场景，包含核心入口、上游、自身、下游。</li>
<li><strong>维度</strong>：机房、时间粒度。实时看板:故障发生时，秒级盘能及时观察业务流量的变化。T+1看板:观察指标在一段时间内的趋势变化</li>
<li><strong>指标</strong>：业务核心指标 &amp; 服务状态指标(服务状态指标：总量、成功量、失败量、耗时、成功率、限流、错误码等)。</li>
</ul>
<h3 id="报警配置">报警配置</h3>
<h4 id="报警降噪">报警降噪</h4>
<ul>
<li><strong>噪音管理</strong>：噪音会降低大家对报警的敏感度，导致忽略真正的问题报警。通过合理配置报警条件和阈值，减少无意义的报警，提高报警的有效性。</li>
</ul>
<h4 id="报警分级">报警分级</h4>
<ul>
<li><strong>告警分级</strong>：采用二八法则，将 80% 的注意力集中在 20% 的重要告警上。通过对报警进行分类，确保关键问题能够被及时关注和处理。</li>
</ul>
<h3 id="故障恢复">故障恢复</h3>
<p>线上问题的第一要务是优先恢复服务。只有在无法找到明确的恢复方式时，才能将重心转移到根因定位上。此时，定位的目的仍然是为了找出恢复的手段。</p>
<ul>
<li><strong>主链路高可用</strong>：提升系统的健壮性，使其在出现问题时能够自愈恢复。</li>
<li><strong>人工手段</strong>：当可用性问题超出自愈能力时，使用回滚、预案等人工手段来恢复服务。若相关应用有变更，优先考虑回滚操作。</li>
</ul>
<h4 id="常见恢复方式">常见恢复方式</h4>
<ol>
<li><strong>回滚</strong>：将系统恢复到上一个稳定版本，适用于有变更的情况。</li>
<li><strong>预案执行</strong>：根据事先制定的应急预案进行处理，确保快速响应。</li>
<li><strong>重启服务</strong>：在服务出现异常时，通过重启服务来恢复功能。</li>
<li><strong>扩容</strong>：在流量激增或资源不足时，进行系统扩容以提高可用性。</li>
<li><strong>故障转移</strong>：将流量切换到备份系统或其他可用实例，确保服务持续可用。</li>
<li><strong>监控与报警</strong>：持续监控系统状态，并及时报警，确保问题能够被及时发现和处理。</li>
</ol>
<p>通过以上策略，可以有效地提高系统的可用性和恢复能力，确保在发生故障时能够快速响应和修复。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[抖音分库分表实践]]></title>
        <id>https://mzhtech.github.io/post/dou-yin-fen-ku-fen-biao-shi-jian/</id>
        <link href="https://mzhtech.github.io/post/dou-yin-fen-ku-fen-biao-shi-jian/">
        </link>
        <updated>2024-09-26T08:25:34.000Z</updated>
        <content type="html"><![CDATA[<h1 id="一-前言">一、前言</h1>
<ul>
<li>
<p><strong>为什么需要分库分表</strong><br>
随着业务的发展，受限于单个主库的 CPU/内存/磁盘 IOPS 的影响，数据库性能接近或者达到上限时，需要分库分表，否则受到数据库瓶颈的限制业务将不能正常开展。</p>
</li>
<li>
<p><strong>分库分表的难度与挑战</strong><br>
下面列出了几个分库分表过程中遇到的核心问题：</p>
<ul>
<li>某笔业务订单的数据库增删查改究竟是以新库为准还是以老库为准？</li>
<li>如何确保业务系统写入新库的数据是正确的，如何发现不一致问题并补偿数据？</li>
<li>依赖的组件故障时，例如 MQ、DSyncer 等，如何容错容灾？</li>
<li>多维度查询、分片数等如何选择，使系统具备良好的稳定性和扩展性？</li>
</ul>
</li>
</ul>
<p>对核心系统进行分库分表操作的难度与挑战，好比对一辆高速行驶中的汽车更换车轮，也就是既要保证“数据库/车轮”的更换成功，又要保证“业务系统/车辆”的正常运行。</p>
<ul>
<li><strong>本文内容</strong><br>
本文介绍了四种分库分表方式，并结合核心系统的平滑改造实践给出了关键问题的选型依据，帮助读者更好地理解本文。</li>
</ul>
<h1 id="二-分库分表的四种方式">二、分库分表的四种方式</h1>
<p>以下用数据库 1 拆 2 为例来说明不同方式进行拆库的流程。</p>
<h2 id="21-主从同步方式">2.1 主从同步方式</h2>
<p>常见链路，即拆库前：</p>
<ol>
<li>
<p><strong>主从同步</strong></p>
<ol>
<li>申请新的两个数据库集群：新集群 1、新集群 2。</li>
<li>将两个新集群的 Master 作为老集群的 Slave。</li>
</ol>
</li>
<li>
<p><strong>订阅切换</strong></p>
<ol>
<li>中间件订阅新集群。</li>
<li>取消老集群的数据订阅。</li>
</ol>
</li>
<li>
<p><strong>流量切换</strong></p>
<ol>
<li>老集群停写，等待新集群追上老集群的数据。</li>
<li>断掉新老集群之间的主从同步。</li>
<li>修改数据库路由规则，让每个集群承担 50% 的读写流量。</li>
</ol>
<p>停写操作有损，具体影响与后续 2 步的操作时长有关，没有灰度过程，直接切换。</p>
</li>
<li>
<p><strong>清理回收</strong></p>
<ol>
<li>老集群下线。</li>
<li>删除新集群中 50% 的冗余数据。</li>
<li>业务代码兼容逻辑删除。</li>
</ol>
</li>
</ol>
<h3 id="优点">优点</h3>
<ol>
<li>简单，几乎没有业务改动，数据一致性由 MySQL Master-Slave 架构保证。</li>
<li>周期短，随时可启动。</li>
</ol>
<h3 id="缺点">缺点</h3>
<ol>
<li>无法灰度，比如流量切到新集群后出现故障，对业务影响太大。</li>
<li>业务有损失，流量切换过程中需要将老集群停写，具体影响与后续 2 步的操作时长有关。</li>
</ol>
<h2 id="22-业务双写方式">2.2 业务双写方式</h2>
<ol>
<li>
<p><strong>增存同步</strong></p>
<ol>
<li>申请两个新的数据库集群并建库建表。</li>
<li>订阅老集群的增量数据分别同步至两个新集群。</li>
<li>将老集群的存量数据分别同步至两个新集群。</li>
<li>校验新老集群的数据一致性。</li>
</ol>
</li>
<li>
<p><strong>业务双写</strong></p>
<ol>
<li>业务在所有写数据库的地方都使用新的路由规则再写一次 2 个新集群。</li>
<li>停止老集群和两个新集群的数据同步。</li>
</ol>
<p>此时由于读流量还在老集群，所以写入的结果仍以老集群的写入结果为准（新集群写入弱依赖，因为无法使用数据库事务）。</p>
</li>
<li>
<p><strong>订阅切换</strong></p>
<ol>
<li>使用数据校验工具校验新老集群的数据是否一致。</li>
<li>中间件订阅两个新集群。</li>
<li>取消老集群的数据订阅任务。</li>
</ol>
</li>
<li>
<p><strong>业务切换</strong></p>
<ol>
<li>读流量使用新的路由规则切换至两个新集群。</li>
</ol>
<p>此时由于读流量在两个新集群，所以写入结果以新路由规则的新集群写入结果为准（老集群写入若依赖，因为无法使用数据库事务）。</p>
</li>
<li>
<p><strong>停止双写</strong></p>
<ol>
<li>关闭一致性校验。</li>
<li>停止对老集群的写入。</li>
</ol>
</li>
<li>
<p><strong>清理回收</strong></p>
<ol>
<li>回收老集群 DB 资源。</li>
<li>删除业务兼容代码。</li>
</ol>
</li>
</ol>
<h3 id="优点-2">优点</h3>
<ol>
<li>可灰度，业务切换过程中可通过万分比灰度放量。</li>
<li>可回滚，在每一步若是有问题都可以及时修改配置来做回滚。</li>
<li>业务基本无损，注意双写接口耗时增加。</li>
</ol>
<h3 id="缺点-2">缺点</h3>
<ol>
<li>复杂，业务控制逻辑复杂，容易出错。</li>
<li>依赖多，涉及到很多临时外部依赖：增量校验工具、存量数据校验工具。</li>
<li>周期长。</li>
<li>数据不一致：双写一致性可能会存在延迟（例如：网络超时时，老库成功，新库失败，延迟导致新库的数据不是最新的，写/强制读主的逻辑会异常）。</li>
</ol>
<h2 id="23-业务双读方式">2.3 业务双读方式</h2>
<ol>
<li>
<p><strong>环境搭建</strong></p>
<ol>
<li>申请新的数据库集群库表。</li>
<li>申请新的订阅任务订阅新的数据库集群。</li>
<li>保持原先的订阅任务不变。</li>
</ol>
</li>
<li>
<p><strong>上线双读</strong></p>
<ol>
<li>上线双读逻辑：所有的读请求，先使用老的路由规则读一次老集群，若是没有读到再使用新的路由规则读一下新集群（双读可以帮我们判断一条记录在老集群还是新集群），此时两个新集群中并没有数据。</li>
</ol>
</li>
<li>
<p><strong>增量切换</strong></p>
<ol>
<li>增量数据（新的 insert 请求以及该条记录后续的 update）写新集群。</li>
<li>存量数据（已经 insert 到老集群的记录的后续的 update）写老集群。</li>
</ol>
</li>
<li>
<p><strong>存量迁移</strong></p>
<ol>
<li>老集群存量数据同步至新集群。</li>
<li>校验存量数据的一致性。</li>
</ol>
</li>
<li>
<p><strong>存量切换</strong></p>
<ol>
<li>先进行数据一致性校验，若出现老集群和新集群不一致，则从老集群向新集群进行补偿。</li>
<li>数据完全一致后，老集群停写，保证操作过程中不会出现不一致。</li>
<li>修改为只读写新集群。</li>
</ol>
</li>
<li>
<p><strong>兼容清理</strong></p>
<ol>
<li>代码兼容逻辑清理。</li>
<li>老集群回收。</li>
</ol>
</li>
</ol>
<h3 id="优点-3">优点</h3>
<ol>
<li>可灰度，在第三步增量写新集群时是可以做灰度逻辑放量的。</li>
<li>业务基本无损，接口耗时增加，新集群中的数据需要访问两次数据库。</li>
</ol>
<h3 id="缺点-3">缺点</h3>
<ol>
<li>复杂，业务控制逻辑复杂，容易出错。</li>
<li>周期长，预计以月为单位。</li>
<li>依赖多，涉及到很多临时外部依赖，比如数据校验。</li>
<li>存量切换过程中一致性保障有停写，可能会有损失。</li>
</ol>
<h2 id="24-流水号打标方式">2.4 流水号打标方式</h2>
<ol>
<li>
<p><strong>环境搭建</strong></p>
<ol>
<li>申请新的数据库集群库表。</li>
</ol>
</li>
<li>
<p><strong>增量切换</strong></p>
<ol>
<li>上线路由变更：SELECT 与 UPDATE 根据流水号携带的标识位判断读写新集群还是老集群。</li>
<li>流水号打标放量：INSERT 时流水号打上“新集群”的标识并将记录写入到新集群。</li>
</ol>
</li>
<li>
<p><strong>存量迁移</strong></p>
<ol>
<li>将老集群中的数据全部迁移至新集群。</li>
<li>校验新老集群中数据的一致性。</li>
</ol>
</li>
<li>
<p><strong>存量切换</strong></p>
<ol>
<li>先进行数据的一致性校验，若出现新老集群不一致，则从老集群向新集群进行补偿。</li>
<li>数据完全一致后老集群停写，保证操作过程中不会出现不一致。</li>
<li>修改为只读写新集群。</li>
</ol>
</li>
<li>
<p><strong>兼容清理</strong></p>
<ol>
<li>代码兼容逻辑清理。</li>
<li>老集群回收。</li>
</ol>
</li>
</ol>
<p>流水号打标就是在流水号生成的时候，标记上该订单是走新库还是老库，流水号打标与业务双读的区别：</p>
<table>
<thead>
<tr>
<th>业务双读</th>
<th>流水号打标</th>
</tr>
</thead>
<tbody>
<tr>
<td>所有的读请求，先使用老的路由规则读一次老集群，若是没有读到再使用新的路由规则读一下新集群（双读可以帮我们判断一条记录在老集群还是新集群）</td>
<td>INSERT、SELECT 与 UPDATE 根据流水号携带的标识位判断读写新集群还是老集群</td>
</tr>
<tr>
<td>可以看出流水号打标方式是业务双读方式的升级版，流程上基本一致，但是不需要读两次数据库，控制逻辑更加简单。</td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="25-方案选型">2.5 方案选型</h2>
<p>具体想用哪种分库分表方式，需要结合具体的业务场景：</p>
<table>
<thead>
<tr>
<th>分库分表方式</th>
<th>方案复杂度</th>
<th>工作量</th>
<th>一致性保障难度</th>
<th>业务影响</th>
<th>灰度能力</th>
<th>组件依赖</th>
<th>出错风险</th>
</tr>
</thead>
<tbody>
<tr>
<td>主从同步</td>
<td>⭐</td>
<td>⭐</td>
<td>⭐</td>
<td>☆☆☆☆☆</td>
<td>☆</td>
<td>⭐</td>
<td>⭐</td>
</tr>
<tr>
<td>业务双写</td>
<td>☆☆☆☆☆</td>
<td>☆☆☆☆☆</td>
<td>☆☆☆☆☆</td>
<td>⭐</td>
<td>⭐⭐⭐⭐⭐</td>
<td>☆☆☆☆☆</td>
<td>☆☆☆☆☆</td>
</tr>
<tr>
<td>业务双读</td>
<td>☆☆☆☆</td>
<td>☆☆☆☆</td>
<td>☆☆☆☆</td>
<td>⭐</td>
<td>⭐⭐⭐⭐⭐</td>
<td>☆☆☆</td>
<td>☆☆☆☆</td>
</tr>
<tr>
<td>流水号打标记</td>
<td>☆☆☆</td>
<td>☆☆☆</td>
<td>☆☆☆☆</td>
<td>⭐</td>
<td>⭐⭐⭐⭐⭐</td>
<td>☆☆☆</td>
<td>☆☆☆</td>
</tr>
</tbody>
</table>
<ul>
<li>
<p><strong>简单业务场景</strong>：</p>
<ul>
<li>如果可以接受不用灰度，建议采用主从同步方式；</li>
<li>如果需要灰度，采用业务双写、业务双读、流水号打标记等方式均可，没有太大差异。</li>
</ul>
</li>
<li>
<p><strong>复杂业务场景</strong>：</p>
<ul>
<li>如果可以接受不用灰度，建议采用主从同步方式。</li>
<li>如果需要灰度，建议采用流水号打标方式。</li>
</ul>
</li>
</ul>
<h1 id="三-分库分表实践">三、分库分表实践</h1>
<h2 id="31-业务背景介绍">3.1 业务背景介绍</h2>
<p>支付核心系统复杂度足够高，下面是分库分表前的数据库现状介绍。</p>
<ul>
<li>
<p><strong>业务现状</strong><br>
直播场景：目前支付大多数情况下 TPS 在 个位数 波动，但开发者/服务商在直播时有秒杀场景，例如某些业务方要求支付链路支持 3000 TPS。<br>
异步入库：因为单片数据库无法支持直播场景的 TPS，临时采用异步入库的方式，但是异步入库在复杂场景下难以维护。</p>
</li>
<li>
<p><strong>数据库上游业务服务现状</strong><br>
数据库上游共 70+ 个 PSM 授权了数据库读写权限：</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>场景</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>服务</td>
<td>10 个+ 包括支付、退款、分账、商户等组内服务，还包括其它团队的服务</td>
</tr>
<tr>
<td>中间件</td>
<td>约 10 个，包括 Tesla、Dsyncer 等中间件</td>
</tr>
<tr>
<td>调度任务</td>
<td>约 50 个，包括支付补单、自动结算、自动提现等脚本</td>
</tr>
<tr>
<td>未知</td>
<td>3 个</td>
</tr>
</tbody>
</table>
<ul>
<li>
<p><strong>数据库表现状</strong><br>
非分片库，DB 支持 TPS 2000+。<br>
共有 30+ 个表，包括需要分库分表的表 10+，商户相关表约 7 个，无需分库分表的表约 5 个，无用表约 4 个，影子表约 5 个。</p>
</li>
<li>
<p><strong>数据库下游 binlog 订阅现状</strong><br>
包括实时数仓、离线数仓、实时对账、数据异构、发票等下游场景。</p>
</li>
</ul>
<h2 id="32-核心问题-解决">3.2 核心问题 &amp; 解决</h2>
<h3 id="321-方案选型">3.2.1 方案选型</h3>
<table>
<thead>
<tr>
<th>方案</th>
<th>是否选择</th>
<th>原因</th>
</tr>
</thead>
<tbody>
<tr>
<td>主从同步方案</td>
<td>✗</td>
<td>不可灰度，业务场景不可接受</td>
</tr>
<tr>
<td>业务双写方案</td>
<td>✗</td>
<td>业务复杂度高，增删查改的地方太多，且涉及大量事务，改动大且复杂，容易出错</td>
</tr>
<tr>
<td>业务双读方案</td>
<td>✗</td>
<td>比流水号打标方案复杂</td>
</tr>
<tr>
<td>流水号打标记方案</td>
<td>✓</td>
<td>可灰度、可回滚、改动小更加可控</td>
</tr>
</tbody>
</table>
<p>核心系统选择了流水号打标记方案进行改造。</p>
<h3 id="322-分片数量的选择">3.2.2 分片数量的选择</h3>
<p>目前最大使用分片支持 9000+ 分片，公司常用分片数为质数 101、251、1009。分片数量该如何选择，是不是分片数量越大越好？</p>
<ul>
<li>
<p><strong>分片数量过小</strong><br>
集群数量上限受到分片数量限制，例如：分片数为 3，那么集群数量最大只能为 3，无法再横向扩展。单分片数据量过大导致慢查询。</p>
</li>
<li>
<p><strong>分片数量过大</strong><br>
分片数越多，需要的链接也越多，降低服务的稳定性。</p>
</li>
<li>
<p><strong>如何选择合适的分片数</strong><br>
一般情况下，建议单个分片的总容量范围在 500 万~5000 万行数据（若单行记录超过 4KB，建议总容量范围不超过 500 万），结合业务未来 2 年的发展情况选择合适的分片数量，核心数据库选择了 251 个分片。</p>
</li>
</ul>
<h3 id="323-分片键sharding-id如何选取">3.2.3 分片键（Sharding ID）如何选取</h3>
<p>核心考虑对事务的支持 &amp;&amp; 大部分（或核心的）SQL 操作或者具备一定并发的 SQL 都是围绕这个分片键进行。下面以核心表的分片键选取为例：</p>
<table>
<thead>
<tr>
<th>Sharding id</th>
<th>是否选取</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td>uid（用户身份）</td>
<td>✗</td>
<td>1. 能够支持现有事务 2. 用户查询订单列表场景无需全集群扫描 3. 如果有账户服务，账户需要 uid 作为分片键</td>
<td>1. 成本高：纯担保支付预下单时没有 uid 2. 需要改造部分表，新增 uid 字段</td>
</tr>
<tr>
<td>ma_app_id（小程序 id）</td>
<td>✗</td>
<td>1. 无需改造表：所有需要分库的表都有 ma_app_id 字段</td>
<td>1. 数据倾斜严重</td>
</tr>
<tr>
<td>order_id（支付订单号）</td>
<td>✓</td>
<td>1. 符合场景：我们场景大部分（或核心的）SQL 操作围绕 order_id 2. 无需改造表：所有需要分库的表都有 order_id 字段 3. 能够支持现有事务</td>
<td>-</td>
</tr>
</tbody>
</table>
<h3 id="324-多维度查询选型">3.2.4 多维度查询选型</h3>
<table>
<thead>
<tr>
<th>方案</th>
<th>描述</th>
<th>缺点</th>
<th>优点</th>
</tr>
</thead>
<tbody>
<tr>
<td>方案一</td>
<td>每个表建立一个对应的索引表</td>
<td>扩展性差：有多少表都建立多少个索引表，索引表过多</td>
<td>-</td>
</tr>
<tr>
<td>方案二</td>
<td>建立大统一索引表，只需要一个索引表</td>
<td>-</td>
<td>扩展性好</td>
</tr>
<tr>
<td>方案三</td>
<td>通过数据异构 ES</td>
<td>有延迟，实时性要求高的场景会查不到单据</td>
<td>支持任何维度的查询</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>索引表的作用</strong>
<ul>
<li>
<p>查询分片键，通过其它单号查询分片键，例如通过 out_order_id 查询 order_id。</p>
</li>
<li>
<p>保证唯一性，分片表只能保证分片键的唯一性，其它唯一索引只在单分片内有效，分片间将失效，例如：</p>
<p>假设 order_id 是分片键，out_order_id 和 ma_app_id 定义的联合唯一索引，如果没有索引表，根据 order_id 分配到不同的分片，out_order_id 和 ma_app_id 即使相同也不会引发唯一键冲突。</p>
</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>order_id</th>
<th>out_order_id</th>
<th>ma_app_id</th>
<th>shard_id</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1234</td>
<td>5678</td>
<td>1</td>
</tr>
<tr>
<td>9</td>
<td>1234</td>
<td>5678</td>
<td>0</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>大统一索引表结构</strong></li>
</ul>
<pre><code class="language-sql">CREATE TABLE `open_payment_index` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',
  `index_no` varchar(256) NOT NULL COMMENT '索引单号',
  `index_type` varchar(64) NOT NULL COMMENT '索引类型',
  `order_id` varchar(128) NOT NULL COMMENT '分片键',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uniq_no_type` (`index_no`,`index_type`)
) ENGINE=InnoDB AUTO_INCREMENT=5403490 DEFAULT CHARSET=utf8mb4 COMMENT='业务索引表';
</code></pre>
<ul>
<li><strong>核心如何支持多维度查询</strong><br>
采用了大统一索引表 + 数据异构 ES 解决方案。</li>
</ul>
<table>
<thead>
<tr>
<th>场景</th>
<th>举例</th>
<th>场景特点</th>
<th>采用方案</th>
</tr>
</thead>
<tbody>
<tr>
<td>实时场景</td>
<td>支付、退款实时链路</td>
<td>实时性要求高</td>
<td>大统一索引表</td>
</tr>
<tr>
<td>运维场景</td>
<td>查询某个商户支付订单</td>
<td>实时性要求低</td>
<td>数据异构 ES</td>
</tr>
</tbody>
</table>
<h3 id="326-分库分表-sdk">3.2.6 分库分表 SDK</h3>
<p>数据库相关的操作统一由 SDK 封装提供，具有减少重复开发、相关逻辑收敛、屏蔽复杂逻辑等优点。</p>
<ul>
<li><strong>索引表</strong></li>
</ul>
<pre><code class="language-go">// CreateIndexRecord 插入索引
func CreateIndexRecord(ctx context.Context, indexNo string, indexType model.IndexTypeEnum, orderID string) error {
  // 1. 参数校验
  // 2. 插入数据库
  // 3. 返回插入结果
}

// QueryIndexRecord 查询索引
func QueryIndexRecord(ctx context.Context, indexNo string, indexType IndexTypeEnum) (string, error) {
  // 1. 参数校验
  // 2. 查询数据库
  // 3. 返回查询结果
}
</code></pre>
<ul>
<li><strong>数据库路由</strong></li>
</ul>
<pre><code class="language-go">// GetShardDB 获取数据库实例
func GetShardDB(ctx context.Context, orderID string) (*gorm.DB, error) {
  // 1. 参数校验
  // 2. 判断打标单号
  // 3. 打标单号走增量开关
  // 4. 非打标单号走存量开关
  // 5. 返回新库实例/老库实例
}
</code></pre>
<h3 id="327-数据一致性保障">3.2.7 数据一致性保障</h3>
<table>
<thead>
<tr>
<th>步骤</th>
<th>操作内容</th>
<th>验证点</th>
<th>回滚步骤</th>
<th>风险</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>新老库数据同步</td>
<td>开启从老库到新库的数据同步</td>
<td>1. 增量 &amp; 存量一致性校验</td>
<td>无需回滚</td>
<td>1. 不一致从老库向新库补偿即可</td>
<td>-</td>
</tr>
<tr>
<td>数据库下游 binlog 订阅迁移</td>
<td>数据库下游 binlog 订阅从老库迁移到新库 topic</td>
<td>1. 迁移前后数据是否一致</td>
<td>回滚：订阅老库 binlog</td>
<td>无</td>
<td>-</td>
</tr>
<tr>
<td>查询类脚本迁移</td>
<td>查询类脚本查老库修改为查新库</td>
<td>1. 脚本执行是否正常</td>
<td>回滚：回滚发布</td>
<td>无</td>
<td>-</td>
</tr>
<tr>
<td>插入索引</td>
<td>增量订单业务系统实时插入，存量订单脚本刷入</td>
<td>1. 索引插入是否正确 2. hive 统计索引插入是否有遗漏</td>
<td>回滚：回滚发布</td>
<td>1. 插入索引遗漏：补偿即可</td>
<td>-</td>
</tr>
<tr>
<td>分库分表-改造代码上线</td>
<td>INSERT、SELECT 和 UPDATE 根据流水号携带的标识位判断读写新集群还是老集群代码改造并上线</td>
<td>1. 所有订单依旧在老库处理</td>
<td>回滚：回滚发布</td>
<td>无</td>
<td>某一个订单走新库还是老库，是通过订单号打标实现的，并且走新老库路由通过 SDK 形式封装，业务无感知。</td>
</tr>
<tr>
<td>灰度放量-增量订单</td>
<td>1. 灰度放量：小程序维度 -&gt; 订单万分比维度 -&gt; 增量全量</td>
<td>1. 单号生成：命中灰度按新规则生成打标单号 2.路由是否符合预期：非打标订单走老库，打标订单走新库</td>
<td>回滚步骤:关闭灰度放量。锁住放量订单，执行预案脚本</td>
<td>灰度及时切回，风险可控。</td>
<td>-</td>
</tr>
</tbody>
</table>
<h1 id="三-分库分表收益">三、分库分表收益</h1>
<p>最终 0 资损 0 事故，暂停老数据库的读写操作 30s，解决了支付、退款、分账分库分表的问题。<br>
分库分表前数据库支持 TPS 为 k，分库分表后暂时部署了 n 个集群支持 TPS 为 n*k，且分库分表后支持横向扩展，理论上最大支持 10W TPS。</p>
<ul>
<li>
<p><strong>业务收益</strong><br>
支持开发者/服务商大型直播诉求。</p>
</li>
<li>
<p><strong>技术收益</strong><br>
解决系统容量瓶颈-DB，使 DB 具备水平扩容能力。</p>
</li>
</ul>
<h1 id="四-经验总结">四、经验总结</h1>
<h2 id="41-分库分表涉及的上下游非常多时如何确保梳理无遗漏">4.1 分库分表涉及的上下游非常多时，如何确保梳理无遗漏？</h2>
<p>存量的数据库上游通过 Proxy监控可以查看全集，存量的数据库下游通过消费者列表查询。<br>
增量的数据库上下游通过 RDS &amp; MQ 管理员严格把关，并做好周知。</p>
<h2 id="42-业务快速迭代如何把控质量">4.2 业务快速迭代，如何把控质量？</h2>
<p>系统在做分库分表技术改造时，会有大量的业务需求并行，业务需求也会涉及到数据库表或者字段的修改，这对改造范围评估和一致性提出了新的考验，需要提前做好分库分表范围同步，即涉及的表、服务以及节奏等，任何新增的表或者字段都是分库分表需要考虑的范围。<br>
分库分表期间的需求需要回归测试分库分表的 case，如果需要长期维护分库分表的逻辑推荐自动化工具，如果是短期维护可以人工回归分库分表的测试用例。</p>
<h2 id="43-涉及改造范围大如何把控质量">4.3 涉及改造范围大，如何把控质量？</h2>
<p>除了流量回放，场景用例回归，测试等常规手段外，具体服务的改造越简单越好，一些复杂的逻辑通过 SDK 的形式进行封装，业务无需感知具体路由逻辑。因为一旦改造复杂且范围大，大概率会出问题。</p>
<h2 id="44-处理和校验的关系">4.4 处理和校验的关系</h2>
<p>处理工具和校验工具最好是分离的，没有校验和补偿大概率会有问题，举两个例子：</p>
<ul>
<li>刷存量索引时，因为历史数据量很大，所以在刷存量索引时，一定会有数据库超时等报错，通常需要补偿一次，因此需要校验索引刷入的完整性，如果有遗漏需要补偿，直到校验通过。</li>
<li>使用工具 DSyncer 进行增存同步时，DSyncer 会有少量的数据丢失问题，所以单一的工具也不是完全可靠，还需要做校验和补偿。</li>
</ul>
<p>所以，不要抱有侥幸心理，单一的脚本或者工具不完全置信，最好能 double check。业务系统同理，除了最基本的接口监控和业务监控外，还需要实时对账和离线对账。</p>
<h2 id="45-容错容灾心得">4.5 容错容灾心得</h2>
<p>业务系统需要处理好强弱依赖，组件异常时的降级和补偿方案。<br>
在分库分表过程中，遇到过“DSyncer 基架迭代导致较长时间内无数据同步”、“DataEyes 特殊场景修复能力 bug”、“MQ 基架 BMQ 集群大面积故障”、“Redis 查询超时较多”等问题。“流水号打标方案”很健壮，提前做好了容错和补偿能力，这些基架问题都未导致业务异常。</p>
<h2 id="46-必须要考虑的几个点">4.6 必须要考虑的几个点</h2>
<table>
<thead>
<tr>
<th>考虑的点</th>
<th>详情</th>
</tr>
</thead>
<tbody>
<tr>
<td>表范围评估</td>
<td>哪些表需要分库分表，可以从以下角度考虑：1. TPS 高的表 2. 和高 TPS 表之间有事务</td>
</tr>
<tr>
<td>影响范围评估</td>
<td>1. 涉及数据库下游有哪些？例离线数仓、对账等 2. 涉及数据库上游有哪些？例服务、脚本、中间件等 3. 同时进行的其它业务、技术等需求对分库分表的影响</td>
</tr>
<tr>
<td>一致性如何保障</td>
<td>1. 业务是否有强一致场景？存量数据是否还会 update？例如何保证读写的数据是最新的 2. 存量数据是否需要最终同步到新库？ 3. 如何及时发现问题？例如业务监控、接口监控、实时/离线对账、数据一致性校验等 4. 极限场景是否有考虑到？例如极限场景的处理、测试等</td>
</tr>
<tr>
<td>可用性</td>
<td>1. 如何容灾？例如降级方案、补偿方案等 2. 业务能否接受停服？能否接受短暂停服？ 3. 数据库如何选型？例偏向于稳定性还是功能强大 4. 分库分表兼容代码下线</td>
</tr>
<tr>
<td>容错性</td>
<td>1. 如何容错？例操作 SOP、回滚方案等</td>
</tr>
<tr>
<td>扩展性</td>
<td>1. 分片键、分片数、多维度查询、唯一索引约束等</td>
</tr>
</tbody>
</table>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[常见的限流算法及自适应]]></title>
        <id>https://mzhtech.github.io/post/chang-jian-de-xian-liu-suan-fa-ji-zi-gua-ying/</id>
        <link href="https://mzhtech.github.io/post/chang-jian-de-xian-liu-suan-fa-ji-zi-gua-ying/">
        </link>
        <updated>2024-09-25T09:36:02.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>在分布式系统中，如果某个服务节点发生故障或者网络发生异常，都有可能导致调用方被阻塞等待。如果超时时间设置很长，调用方资源很可能被耗尽。这又导致了调用方的上游系统发生资源耗尽的情况，最终导致系统雪崩。</p>
<p>要防止系统发生雪崩，就必须要有容错设计。如果遇到突增流量，一般的做法是对非核心业务功能采用熔断和服务降级的措施来保护核心业务功能正常服务，而对于核心功能服务，则需要采用限流的措施。</p>
<p>今天我们来聊一聊系统容错中的限流、熔断和服务降级，并主要对限流的经典算法进行分析。</p>
<p>相信你看完本篇文章，一定能够对系统容错的常见策略——限流、熔断、降级有更深的理解和体会。</p>
<h2 id="概述">概述</h2>
<h3 id="1-熔断客户端">1. 熔断（客户端）</h3>
<p>在服务的依赖调用中，被调用方出现故障时，出于自我保护的目的，调用方会主动停止调用，并根据业务需要进行相应处理。调用方这种主动停止调用的行为我们称之为熔断。</p>
<h4 id="为什么要熔断">为什么要熔断？</h4>
<p>假定服务A依赖服务B，当服务B处于正常状态，整个调用是健康的，服务A可以得到服务B的正常响应。当服务B出现故障时，比如响应缓慢或者响应超时，如果服务A继续请求服务B，那么服务A的响应时间也会增加，进而导致服务A响应缓慢。如果服务A不进行熔断处理，服务B的故障会传导至服务A，最终导致服务A也不可用。</p>
<h3 id="2-限流服务端">2. 限流（服务端）</h3>
<p>限流是针对服务请求数量的一种自我保护机制，当请求数量超出服务的处理能力时，会自动丢弃新来的请求。</p>
<h4 id="为什么要限流">为什么要限流？</h4>
<p>任何一个系统的处理能力都是有极限的，假定服务A的处理能力为QPS=100，当QPS&lt;100时服务A可以提供正常的服务。当QPS&gt;100时，由于请求量增大，会出现争抢服务资源的情况（数据库连接、CPU、内存等），导致服务A处理缓慢；当QPS继续增大时，可能会造成服务A响应更加缓慢甚至奔溃。如果不进行限流控制，服务A始终会面临着被大流量冲击的风险。做好系统请求流量的评估，制定合理的限流策略，是我们进行系统高可用保护的第一步。</p>
<h3 id="3-降级">3. 降级</h3>
<p>降级是通过开关配置将某些不重要的业务功能屏蔽掉，以提高服务处理能力。在大促场景中经常会对某些服务进行降级处理，大促结束之后再进行复原。</p>
<h4 id="为什么要降级">为什么要降级？</h4>
<p>在不影响业务核心链路的情况下，屏蔽某些不重要的业务功能，可以节省系统的处理时间，提供系统的响应能力，在服务器资源固定的前提下处理更多的请求。</p>
<h2 id="熔断">熔断</h2>
<p>无论是令牌桶、漏桶还是自适应限流的方法，总的来说都是服务端的单机限流方式。虽然服务端限流可以帮助我们抗住一定的压力，但是拒绝请求毕竟还是有成本的。如果我们的本来流量可以支撑1w QPS，加了限流可以支撑在10w QPS的情况下仍然可以提供1w QPS的有效请求，但是流量突然再翻了10倍，来到100w QPS，那么服务该挂还是得挂。</p>
<p>所以我们的可用性建设不仅仅是服务端做建设就可以万事大吉了，得在整个链路上的每个组件都做好自己的事情才行，今天我们就来一起看一下客户端上的限流措施：熔断。</p>
<p>熔断器存在三种状态：</p>
<ul>
<li><strong>关闭 (closed)</strong>: 关闭状态下没有触发断路保护，所有的请求都正常通行。</li>
<li><strong>打开 (open)</strong>: 当错误阈值触发之后，就进入开启状态，这个时候所有的流量都会被节流，不运行通行。</li>
<li><strong>半打开 (half-open)</strong>: 处于打开状态一段时间之后，会尝试放行一个流量来探测当前 server 端是否可以接收新流量，如果没有问题就会进入关闭状态，如果有问题又会回到打开状态。</li>
</ul>
<h2 id="方案对比">方案对比</h2>
<h3 id="hystrix-go">Hystrix-Go</h3>
<p>熔断器中比较典型的实现就是 Hystrix。</p>
<p><strong>参考链接</strong>：<a href="%E9%93%BE%E6%8E%A5">hystrix-go 使用与原理 | Go 技术论坛</a></p>
<p>Hystrix 是由 Netflix 开发的一款开源组件，提供了基础的熔断功能。Hystrix 将降级的策略封装在 Command 中，提供了 run 和 fallback 两个方法，前者表示正常的逻辑，比如微服务之间的调用……如果发生了故障，再执行 fallback 方法返回结果，我们可以把它理解成保底操作。如果正常逻辑在短时间内频繁发生故障，那么可能会触发短路，也就是之后的请求不再执行 run，而是直接执行 fallback。</p>
<p>更多关于 Hystrix 的信息可以查看 <a href="https://github.com/Netflix/Hystrix">GitHub</a>，而 Hystrix-Go 则是用 Go 实现的 Hystrix 版，更确切的说，是简化版。</p>
<h3 id="使用方法">使用方法：</h3>
<p>Hystrix 实现熔断一般包括两步：</p>
<ol>
<li><strong>配置熔断规则</strong></li>
<li><strong>设置熔断逻辑</strong></li>
</ol>
<p>一个简单的🌰：</p>
<pre><code class="language-go">// 第一步：配置熔断规则
hystrix.ConfigureCommand(&quot;wuqq&quot;, hystrix.CommandConfig{
        Timeout:                int(3 * time.Second),
        MaxConcurrentRequests:  10,
        SleepWindow:            5000,
        RequestVolumeThreshold: 10,
        ErrorPercentThreshold:  30,
    })

// 第二步：设置熔断逻辑
// Do 是异步，Go 是同步

_ = hystrix.Do(&quot;wuqq&quot;, func() error {
    // talk to other services
    _, err := http.Get(&quot;https://www.baidu.com/&quot;)
    if err != nil {
        fmt.Println(&quot;get error:%v&quot;, err)
        return err
    }
    return nil
}, func(err error) error {
    fmt.Printf(&quot;handle error:%v\n&quot;, err)
    return nil
})
</code></pre>
<p><strong>Do 函数需要三个参数</strong>，第一个参数是 command 名称，你可以把每个名称当成一个独立的服务，第二个参数是处理正常的逻辑，比如 HTTP 调用服务，返回参数是 err。如果处理调用失败，那么就执行第三个参数逻辑，我们称为保底操作。由于服务错误率过高导致熔断器开启，那么之后的请求也直接回调此函数。</p>
<h3 id="配置参数含义">配置参数含义：</h3>
<ul>
<li><strong>Timeout</strong>: 执行 command 的超时时间。</li>
<li><strong>MaxConcurrentRequests</strong>: command 的最大并发量。</li>
<li><strong>SleepWindow</strong>: 当熔断器被打开后，SleepWindow 的时间就是控制过多久后去尝试服务是否可用了。</li>
<li><strong>RequestVolumeThreshold</strong>: 一个统计窗口 10 秒内请求数量。达到这个请求数量后才去判断是否要开启熔断。</li>
<li><strong>ErrorPercentThreshold</strong>: 错误百分比，请求数量大于等于 RequestVolumeThreshold 并且错误率到达这个百分比后就会启动熔断。</li>
</ul>
<h3 id="核心实现">核心实现</h3>
<p>核心实现的方法是 AllowRequest，IsOpen 判断当前是否处于熔断状态，allowSingleTest 就是去看是否过了一段时间需要重新进行尝试。</p>
<pre><code class="language-go">func (circuit *CircuitBreaker) AllowRequest() bool {        
    return !circuit.IsOpen() || circuit.allowSingleTest()
}

func (circuit *CircuitBreaker) IsOpen() bool {
   circuit.mutex.RLock()
   o := circuit.forceOpen || circuit.open
   circuit.mutex.RUnlock()

   if o {
      return true
   }

   if uint64(circuit.metrics.Requests().Sum(time.Now())) &lt; getSettings(circuit.Name).RequestVolumeThreshold {
      return false
   }

   if !circuit.metrics.IsHealthy(time.Now()) {
      // too many failures, open the circuit
      circuit.setOpen()
      return true
   }

   return false
}
</code></pre>
<p>Hystrix-Go 已经可以比较好地满足我们的需求，但是存在一个问题就是一旦触发了熔断，在一段时间之内就会被一刀切地拦截请求，所以我们来看看 Google SRE 的一个实现。</p>
<h2 id="google-sre保护算法">Google SRE保护算法</h2>
<p>这个算法的好处是不会直接一刀切的丢弃所有请求，而是计算出一个概率来进行判断。当成功的请求数量越少，K 越小的时候计算出的概率就越大，表示这个请求被丢弃的概率越大。</p>
<h3 id="kratos源码分析">Kratos源码分析</h3>
<pre><code class="language-go">func (b *sreBreaker) Allow() error {
   // 统计成功的请求，和总的请求
   success, total := b.summary()

   // 计算当前的成功率
   k := b.k * float64(success)
   if log.V(5) {
      log.Info(&quot;breaker: request: %d, succeed: %d, fail: %d&quot;, total, success, total-success)
   }
   // 统计请求量和成功率
   // 如果 qps 比较小，不触发熔断
   // 如果成功率比较高，不触发熔断，如果 k = 2，那么就是成功率 &gt;= 50% 的时候就不熔断
   if total &lt; b.request || float64(total) &lt; k {
      if atomic.LoadInt32(&amp;b.state) == StateOpen {
         atomic.CompareAndSwapInt32(&amp;b.state, StateOpen, StateClosed)
      }
      return nil
   }
   if atomic.LoadInt32(&amp;b.state) == StateClosed {
      atomic.CompareAndSwapInt32(&amp;b.state, StateClosed, StateOpen)
   }

   // 计算一个概率，当 dr 值越大，那么被丢弃的概率也就越大
   // dr 值是，如果失败率越高或者是 k 值越小，那么它越大
   dr := math.Max(0, (float64(total)-k)/float64(total+1))
   drop := b.trueOnProba(dr)
   if log.V(5) {
      log.Info(&quot;breaker: drop ratio: %f, drop: %t&quot;, dr, drop)
   }
   if drop {
      return ecode.ServiceUnavailable
   }
   return nil
}

// 通过随机来判断是否需要进行熔断
func (b *sreBreaker) trueOnProba(proba float64) (truth bool) {
   b.randLock.Lock()
   truth = b.r.Float64() &lt; proba
   b.randLock.Unlock()
   return
}
</code></pre>
<p><strong>参考链接</strong>：<a href="%E9%93%BE%E6%8E%A5">Go可用性(六) 熔断 - Mohuishou</a></p>
<h2 id="熔断与-failover-结合的思想">熔断与 Failover 结合的思想</h2>
<p>一句话总结：请求先进入 CircuitBreaker 根据当前熔断器策略决定请求主集群或备集群，若请求主集群且主集群请求失败，则进入 Failover 逻辑 Failover 到备集群中获取数据。</p>
<p><strong>参考链接</strong>：<a href="%E9%93%BE%E6%8E%A5">CS-SP-Relation-40-Stability - 通用自动容灾组件方案</a></p>
<h2 id="限流">限流</h2>
<p>限流，也称流量控制。是指系统在面临高并发，或者大流量请求的情况下，限制新的请求对系统的访问，从而保证系统的稳定性。限流会导致部分用户请求处理不及时或者被拒，这就影响了用户体验。所以一般需要在系统稳定和用户体验之间平衡一下。</p>
<h3 id="1-固定窗口">1. 固定窗口</h3>
<p>固定时间内对请求数进行限制，例如说每秒请求不超过50次，那就在0-1秒，1-2秒……n-n+1秒，每秒不超过50次请求。</p>
<p>可是会出现一个问题，在0.99秒和1.01秒分别有50次请求，对于固定窗口方法，不会限流，但是实际上在0.99秒-1.01秒，这一段不到1s的时间内已经达到了阀值的两倍，以下的滑动窗口方法可以解决这个问题。</p>
<h3 id="2-滑动窗口">2. 滑动窗口</h3>
<h4 id="算法思想">算法思想</h4>
<p>滑动时间窗口算法，是对普通时间窗口计数的优化。</p>
<p>使用普通时间窗口时，我们会为每个 user_id/ip 维护一个 KV: uidOrIp: timestamp_requestCount。假设限制1秒1000个请求，那么第100ms有一个请求，这个 KV 变成 uidOrIp: timestamp_1，递200ms有1个请求，我们先比较距离记录的 timestamp 有没有超过1s，如果没有只更新 count，此时 KV 变成 uidOrIp: timestamp_2。当第1100ms来一个请求时，更新记录中的 timestamp 并重置计数，KV 变成 uidOrIp: newtimestamp_1。</p>
<p>普通时间窗口有一个问题，假设有500个请求集中在前1s的后100ms，500个请求集中在后1s的前100ms，其实在这200ms内已经请求超限了，但是由于时间窗每经过1s就会重置计数，就无法识别到此时的请求超限。</p>
<p>对于滑动时间窗口，我们可以把1ms的时间窗口划分成10个 time slot，每个 time slot 统计某个100ms的请求数量。每经过100ms，有一个新的 time slot 加入窗口，早于当前时间100ms的 time slot 出窗口。窗口内最多维护10个 time slot，储存空间的消耗同样是比较低的。</p>
<h4 id="适用场景">适用场景</h4>
<p>与令牌桶一样，有应对突发流量的能力。</p>
<h3 id="go语言实现">Go语言实现</h3>
<p>主要就是实现 sliding window 算法。可以参考 Bilibili 开源的 kratos 框架里 circuit breaker 用循环列表保存 time slot 对象的实现，他们这个实现的好处是不用频繁的创建和销毁 time slot 对象。下面给出一个简单的基本实现：</p>
<pre><code class="language-go">package main

import (
        &quot;fmt&quot;
        &quot;sync&quot;
        &quot;time&quot;
)

var winMu map[string]*sync.RWMutex

func init() {
        winMu = make(map[string]*sync.RWMutex)
}

type timeSlot struct {
        timestamp time.Time // 这个 timeSlot 的时间起点
        count     int       // 落在这个 timeSlot 内的请求数
}

func countReq(win []*timeSlot) int {
        var count int
        for _, ts := range win {
                count += ts.count
        }
        return count
}

type SlidingWindowLimiter struct {
        SlotDuration time.Duration // time slot 的长度
        WinDuration  time.Duration // sliding window 的长度
        numSlots     int           // window 内最多有多少个 slot
        windows      map[string][]*timeSlot
        maxReq       int // win duration 内允许的最大请求数
}

func NewSliding(slotDuration time.Duration, winDuration time.Duration, maxReq int) *SlidingWindowLimiter {
        return &amp;SlidingWindowLimiter{
                SlotDuration: slotDuration,
                WinDuration:  winDuration,
                numSlots:     int(winDuration / slotDuration),
                windows:      make(map[string][]*timeSlot),
                maxReq:       maxReq,
        }
}

// 获取 user_id/ip 的时间窗口
func (l *SlidingWindowLimiter) getWindow(uidOrIp string) []*timeSlot {
        win, ok := l.windows[uidOrIp]
        if !ok {
                win = make([]*timeSlot, 0, l.numSlots)
        }
        return win
}

func (l *SlidingWindowLimiter) storeWindow(uidOrIp string, win []*timeSlot) {
        l.windows[uidOrIp] = win
}

func (l *SlidingWindowLimiter) validate(uidOrIp string) bool {
        // 同一 user_id/ip 并发安全
        mu, ok := winMu[uidOrIp]
        if !ok {
                var m sync.RWMutex
                mu = &amp;m
                winMu[uidOrIp] = mu
        }
        mu.Lock()
        defer mu.Unlock()

        win := l.getWindow(uidOrIp)
        now := time.Now()
        // 已经过期的 time slot 移出时间窗
        timeoutOffset := -1
        for i, ts := range win {
                if ts.timestamp.Add(l.WinDuration).After(now) {
                        break
                }
                timeoutOffset = i
        }
        if timeoutOffset &gt; -1 {
                win = win[timeoutOffset+1:]
        }

        // 判断请求是否超限
        var result bool
        if countReq(win) &lt; l.maxReq {
                result = true
        }

        // 记录这次的请求数
        var lastSlot *timeSlot
        if len(win) &gt; 0 {
                lastSlot = win[len(win)-1]
                if lastSlot.timestamp.Add(l.SlotDuration).Before(now) {
                        lastSlot = &amp;timeSlot{timestamp: now, count: 1}
                        win = append(win, lastSlot)
                } else {
                        lastSlot.count++
                }
        } else {
                lastSlot = &amp;timeSlot{timestamp: now, count: 1}
                win = append(win, lastSlot)
        }

        l.storeWindow(uidOrIp, win)

        return result
}

func (l *SlidingWindowLimiter) getUidOrIp() string {
        return &quot;127.0.0.1&quot;
}

func (l *SlidingWindowLimiter) IsLimited() bool {
        return !l.validate(l.getUidOrIp())
}

func main() {
        limiter := NewSliding(100*time.Millisecond, time.Second, 10)
        for i := 0; i &lt; 5; i++ {
                fmt.Println(limiter.IsLimited())
        }
        time.Sleep(100 * time.Millisecond)
        for i := 0; i &lt; 5; i++ {
                fmt.Println(limiter.IsLimited())
        }
        fmt.Println(limiter.IsLimited())
        for _, v := range limiter.windows[limiter.getUidOrIp()] {
                fmt.Println(v.timestamp, v.count)
        }

        fmt.Println(&quot;a thousand years later...&quot;)
        time.Sleep(time.Second)
        for i := 0; i &lt; 7; i++ {
                fmt.Println(limiter.IsLimited())
        }
        for _, v := range limiter.windows[limiter.getUidOrIp()] {
                fmt.Println(v.timestamp, v.count)
        }
}
</code></pre>
<h3 id="3-漏桶">3. 漏桶</h3>
<h4 id="算法思想-2">算法思想</h4>
<p>与令牌桶是“反向”的算法，当有请求到来时先放到木桶中，worker 以固定的速度从木桶中取出请求进行响应。如果木桶已经满了，直接返回请求频率超限的错误码或者页面。</p>
<h4 id="适用场景-2">适用场景</h4>
<p>流量最均匀的限流方式，一般用于流量“整形”，例如保护数据库的限流。先把对数据库的访问加入到木桶中，worker 再以 db 能够承受的 QPS 从木桶中取出请求，去访问数据库。不太适合电商抢购和微博出现热点事件等场景的限流，一是应对突发流量不是很灵活，二是为每个 user_id/ip 维护一个队列（木桶），worker 从这些队列中拉取任务，资源的消耗会比较大。</p>
<h3 id="go语言实现-2">Go语言实现</h3>
<p>通常使用队列来实现，在 Go 语言中可以通过 buffered channel 来快速实现，任务加入 channel，开启一定数量的 worker 从 channel 中获取任务执行。</p>
<pre><code class="language-go">package main

import (
        &quot;fmt&quot;
        &quot;sync&quot;
        &quot;time&quot;
)

// 每个请求来了，把需要执行的业务逻辑封装成 Task，放入木桶，等待 worker 取出执行
type Task struct {
        handler func() Result // worker 从木桶中取出请求对象后要执行的业务逻辑函数
        resChan chan Result   // 等待 worker 执行并返回结果的 channel
        taskID  int
}

//封装业务逻辑的执行结果
type Result struct {}

// 模拟业务逻辑的函数
func handler() Result {
        time.Sleep(300 * time.Millisecond)
        return Result{}
}

func NewTask(id int) Task {
        return Task{
                handler: handler,
                resChan: make(chan Result),
                taskID:  id,
        }
}

// 漏桶
type LeakyBucket struct {
        BucketSize int       // 木桶的大小
        NumWorker  int       // 同时从木桶中获取任务执行的 worker 数量
        bucket     chan Task // 存放任务的木桶
}

func NewLeakyBucket(bucketSize int, numWorker int) *LeakyBucket {
        return &amp;LeakyBucket{
                BucketSize: bucketSize,
                NumWorker:  numWorker,
                bucket:     make(chan Task, bucketSize),
        }
}

func (b *LeakyBucket) validate(task Task) bool {
        // 如果木桶已经满了，返回 false
        select {
        case b.bucket &lt;- task:
        default:
                fmt.Printf(&quot;request[id=%d] is refused\n&quot;, task.taskID)
                return false
        }

        // 等待 worker 执行
        &lt;-task.resChan
        fmt.Printf(&quot;request[id=%d] is run\n&quot;, task.taskID)
        return true
}

func (b *LeakyBucket) Start() {
        // 开启 worker 从木桶拉取任务执行
        go func() {
                for i := 0; i &lt; b.NumWorker; i++ {
                        go func() {
                                for {
                                        task := &lt;-b.bucket
                                        result := task.handler()
                                        task.resChan &lt;- result
                                }
                        }()
                }
        }()
}

func main() {
        bucket := NewLeakyBucket(10, 4)
        bucket.Start()

        var wg sync.WaitGroup
        for i := 0; i &lt; 20; i++ {
                wg.Add(1)
                go func(id int) {
                        defer wg.Done()
                        task := NewTask(id)
                        bucket.validate(task)
                }(i)
        }
        wg.Wait()
}
</code></pre>
<h3 id="常见调包使用">常见调包使用</h3>
<ul>
<li><strong>ratelimit package</strong> - <code>go.uber.org/ratelimit</code></li>
</ul>
<h3 id="4-令牌桶">4. 令牌桶</h3>
<h4 id="算法思想-3">算法思想</h4>
<p>令牌桶是目前使用比较广泛的限流方式。</p>
<p>想象有一个木桶，以固定的速度往木桶里加入令牌，木桶满了则不再加入令牌。服务收到请求时尝试从木桶中取出一个令牌，如果能够得到令牌则继续执行后续的业务逻辑；如果没有得到令牌，直接返回请求频率超限的错误码或页面等，不继续执行后续的业务逻辑。</p>
<p><strong>特点</strong>：由于木桶内只要有令牌，请求就可以被处理，所以令牌桶算法可以支持突发流量。同时由于往木桶添加令牌的速度是固定的，且木桶的容量有上限，所以单位时间内处理的请求数也能够得到控制，起到限流的目的。假设加入令牌的速度为 1 token/10ms，桶的容量为500，在请求比较少的时候（小于每10毫秒1个请求）时，木桶可以先&quot;攒&quot;一些令牌（最多500个）。当有突发流量时，一下把木桶内的令牌取空，也就是有500个在并发执行的业务逻辑，之后要等每10ms补充一个新的令牌才能接收一个新的请求。</p>
<p><strong>令牌桶在接收请求速度上进行限制，漏桶在处理请求速度上进行限制。</strong></p>
<h4 id="参数设置">参数设置</h4>
<ul>
<li><strong>木桶的容量</strong> - 考虑业务逻辑的资源消耗和机器能承载并发处理多少业务逻辑。</li>
<li><strong>生成令牌的速度</strong> - 太慢的话起不到“攒”令牌应对突发流量的效果。</li>
</ul>
<h4 id="适用场景-3">适用场景</h4>
<p>适合电商抢购或者微博出现热点事件这种场景，因为在限流的同时可以应对一定的突发流量。如果采用均匀速度处理请求的算法，在发生热点事件的时候，会造成大量的用户无法访问，对用户体验的损害比较大。</p>
<h3 id="go语言实现-3">Go语言实现</h3>
<p>假设每100ms生产一个令牌，按 user_id/IP 记录访问最近一次访问的时间戳 t_last 和令牌数，每次请求时如果 now - last &gt; 100ms, 增加 (now - last) / 100ms 个令牌。然后，如果令牌数 &gt; 0，令牌数 -1 继续执行后续的业务逻辑，否则返回请求频率超限的错误码或页面。</p>
<pre><code class="language-go">package main

import (
        &quot;fmt&quot;
        &quot;sync&quot;
        &quot;time&quot;
)

// 并发访问同一个 user_id/ip 的记录需要上锁
var recordMu map[string]*sync.RWMutex

func init() {
        recordMu = make(map[string]*sync.RWMutex)
}

func max(a, b int) int {
        if a &gt; b {
                return a
        }
        return b
}

type TokenBucket struct {
        BucketSize int // 木桶内的容量：最多可以存放多少个令牌
        TokenRate  time.Duration // 多长时间生成一个令牌
        records    map[string]*record // 记录 user_id/ip 的访问记录
}

// 上次访问时的时间戳和令牌数
type record struct {
        last  time.Time
        token int
}

func NewTokenBucket(bucketSize int, tokenRate time.Duration) *TokenBucket {
        return &amp;TokenBucket{
                BucketSize: bucketSize,
                TokenRate:  tokenRate,
                records:    make(map[string]*record),
        }
}

func (t *TokenBucket) getUidOrIp() string {
        // 获取请求用户的 user_id 或者 ip 地址
        return &quot;127.0.0.1&quot;
}

// 获取这个 user_id/ip 上次访问时的时间戳和令牌数
func (t *TokenBucket) getRecord(uidOrIp string) *record {
        if r, ok := t.records[uidOrIp]; ok {
                return r
        }
        return &amp;record{}
}

// 保存 user_id/ip 最近一次请求时的时间戳和令牌数量
func (t *TokenBucket) storeRecord(uidOrIp string, r *record) {
        t.records[uidOrIp] = r
}

// 验证是否能获取一个令牌
func (t *TokenBucket) validate(uidOrIp string) bool {
        // 并发修改同一个用户的记录上写锁
        rl, ok := recordMu[uidOrIp]
        if !ok {
                var mu sync.RWMutex
                rl = &amp;mu
                recordMu[uidOrIp] = rl
        }
        rl.Lock()
        defer rl.Unlock()

        r := t.getRecord(uidOrIp)
        now := time.Now()
        if r.last.IsZero() {
                // 第一次访问初始化为最大令牌数
                r.last, r.token = now, t.BucketSize
        } else {
                if r.last.Add(t.TokenRate).Before(now) {
                        // 如果与上次请求的间隔超过了 token rate
                        // 则增加令牌，更新 last
                        r.token += max(int(now.Sub(r.last)/t.TokenRate), t.BucketSize)
                        r.last = now
                }
        }
        var result bool
        if r.token &gt; 0 {
                // 如果令牌数大于1，取走一个令牌，validate 结果为 true
                r.token--
                result = true
        }

        // 保存最新的 record
        t.storeRecord(uidOrIp, r)
        return result
}

// 返回是否被限流
func (t *TokenBucket) IsLimited() bool {
        return !t.validate(t.getUidOrIp())
}

func main() {
        tokenBucket := NewTokenBucket(5, 100*time.Millisecond)
        for i := 0; i &lt; 6; i++ {
                fmt.Println(tokenBucket.IsLimited())
        }
        time.Sleep(100 * time.Millisecond)
        fmt.Println(tokenBucket.IsLimited())
}
</code></pre>
<h3 id="常见调包使用-2">常见调包使用</h3>
<ul>
<li><strong>golang.org/x/time/rate</strong></li>
</ul>
<h3 id="5-自适应限流">5. 自适应限流</h3>
<p>漏桶和令牌桶都会有一个问题就是需要提前设置阀值，但是阀值怎么设定，是否合理是个问题。一般我们需要压测来设定，但是工作量很大，而且不能动态变化。</p>
<p>本质上就是通过获取线上业务动态变化来更新限流策略。</p>
<p>我们需要一个数据来做启发阈值，只要这个指标达到了阈值那我们就进入流控当中。常见的选择一般是 CPU、Memory、System Load，这里我们以 CPU 为例。</p>
<p>只要我们的 CPU 负载超过 80% 的时候，获取过去 5s 的最大吞吐数据，然后再统计当前系统中的请求数量，只要当前系统中的请求数大于最大吞吐那么我们就丢弃这个请求。</p>
<h3 id="sentinelalibaba">Sentinel（Alibaba）</h3>
<p>随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 是面向分布式服务架构的流量控制组件，主要以流量为切入点，从流量控制、熔断降级、系统自适应保护等多个维度来帮助您保障微服务的稳定性。</p>
<h4 id="sentinel使用文档">Sentinel使用文档</h4>
<p>用户接入使用 Sentinel Go 主要需要以下几步：</p>
<ol>
<li>对 Sentinel 的运行环境进行相关配置并初始化。API 接口使用细节可以参考：配置方式。</li>
<li>埋点（定义资源），该步骤主要是确定系统中有哪些资源需要防护，资源定义可参考：新手指南。</li>
<li>配置规则，该步骤主要是为每个资源都配置具体的规则，规则的配置可参考：新手指南 以及各个模块的使用文档。</li>
<li>编写资源防护的入口和出口代码。释放方式可参考：新手指南。</li>
</ol>
<p>针对埋点资源配置相应的规则，来达到流量控制的效果。目前 Sentinel 支持五种规则：</p>
<ul>
<li>流控规则</li>
<li>流量隔离规则</li>
<li>熔断规则</li>
<li>自适应流控规则</li>
<li>热点参数流控规则</li>
</ul>
<h3 id="一个简单的例子sentinel-go-接入-demo">一个简单的例子：Sentinel Go 接入 demo</h3>
<pre><code class="language-go">import (
        sentinel &quot;github.com/alibaba/sentinel-golang/api&quot;
)

func main() {
        // 第一步：务必先进行初始化
        err := sentinel.InitDefault()
        if err != nil {
                log.Fatal(err)
        }

        // 第三步：为每个资源配置限流规则
        _, err = flow.LoadRules([]*flow.Rule{
                {
                        Resource:               &quot;some-test&quot;,
                        Threshold:              10,
                        TokenCalculateStrategy: flow.Direct,
                        ControlBehavior:        flow.Reject,
                },
        })
        if err != nil {
                fmt.Println(err)
                return
        }

        ch := make(chan struct{})
        for i := 0; i &lt; 10; i++ {
                go func() {
                        for {
                                // 第二步：埋点逻辑，埋点资源名为 some-test
                                e, b := sentinel.Entry(&quot;some-test&quot;)
                                if b != nil {
                                        // 达到限流：请求被拒绝，在此处进行处理
                                        time.Sleep(time.Duration(rand.Uint64()%10) * time.Millisecond)
                                } else {
                                        // 为达到限流：请求允许通过，此处编写业务逻辑
                                        fmt.Println(util.CurrentTimeMillis(), &quot;Passed&quot;)
                                        time.Sleep(time.Duration(rand.Uint64()%10) * time.Millisecond)

                                        // 务必保证业务结束后调用 Exit
                                        e.Exit()
                                }
                        }
                }()
        }
        &lt;-ch
}
</code></pre>
<h3 id="自适应流控规则">自适应流控规则</h3>
<p><strong>rule 字段</strong>：</p>
<pre><code class="language-go">// Rule describes the policy for system resiliency.
type Rule struct {
        // ID represents the unique ID of the rule (optional).
        ID string `json:&quot;id,omitempty&quot;`
        // MetricType indicates the type of the trigger metric.
        MetricType MetricType `json:&quot;metricType&quot;`
        // TriggerCount represents the lower bound trigger of the adaptive strategy.
        // Adaptive strategies will not be activated until target metric has reached the trigger count.
        TriggerCount float64 `json:&quot;triggerCount&quot;`
        // Strategy represents the adaptive strategy.
        Strategy AdaptiveStrategy `json:&quot;strategy
        // MetricType indicates the type of the trigger metric.
        MetricType MetricType `json:&quot;metricType&quot;`
        // Threshold represents the threshold value for the rule.
        Threshold float64 `json:&quot;threshold&quot;`
        // ControlBehavior defines the behavior when the threshold is exceeded.
        ControlBehavior ControlBehavior `json:&quot;controlBehavior&quot;`
        // Count represents the count of requests to trigger the rule.
        Count int `json:&quot;count,omitempty&quot;`
        // Duration defines the time window for the rule.
        Duration time.Duration `json:&quot;duration,omitempty&quot;`
}
</code></pre>
<h3 id="自适应流控示例">自适应流控示例</h3>
<p>自适应流控规则可以根据系统的实时负载动态调整限流阈值。以下是一个简单的示例，展示如何使用 Sentinel 的自适应流控功能：</p>
<pre><code class="language-go">import (
        &quot;github.com/alibaba/sentinel-golang/api&quot;
        &quot;github.com/alibaba/sentinel-golang/core/flow&quot;
)

func main() {
        // 初始化 Sentinel
        err := sentinel.InitDefault()
        if err != nil {
                log.Fatal(err)
        }

        // 配置自适应流控规则
        _, err = flow.LoadRules([]*flow.Rule{
                {
                        Resource:               &quot;adaptive-resource&quot;,
                        Threshold:              100,
                        ControlBehavior:        flow.SmoothBreach,
                        MetricType:            flow.QPS,
                        Count:                  10,
                        Duration:               10 * time.Second,
                },
        })
        if err != nil {
                log.Fatal(err)
        }

        // 模拟请求
        for i := 0; i &lt; 200; i++ {
                go func() {
                        e, b := sentinel.Entry(&quot;adaptive-resource&quot;)
                        if b != nil {
                                // 达到限流，处理拒绝逻辑
                                fmt.Println(&quot;Request rejected&quot;)
                        } else {
                                // 处理请求
                                fmt.Println(&quot;Request passed&quot;)
                                e.Exit()
                        }
                }()
        }
        time.Sleep(5 * time.Second)
}
</code></pre>
<h3 id="总结">总结</h3>
<p>通过以上的内容，我们深入探讨了系统容错的几种常见策略，包括熔断、限流和服务降级。每种策略都有其独特的实现方式和适用场景。根据不同的业务需求和系统架构，选择合适的容错机制能够有效提升系统的稳定性和可用性。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[业务开发日常工作的方法论]]></title>
        <id>https://mzhtech.github.io/post/ye-wu-kai-fa-ri-chang-gong-zuo-de-fang-fa-lun/</id>
        <link href="https://mzhtech.github.io/post/ye-wu-kai-fa-ri-chang-gong-zuo-de-fang-fa-lun/">
        </link>
        <updated>2024-09-25T08:47:58.000Z</updated>
        <content type="html"><![CDATA[<h1 id="定位">定位</h1>
<h2 id="业务研发的认知">业务研发的认知</h2>
<p>作为一名业务研发同学，就是在某一块业务领域里的研发，需要重视业务领域知识的吸收，尝试成为业务领域的专家。</p>
<p>业务研发除了更好地去交付之外，还应该去掌握你所在的业务领域的领域知识。以社区为例，可以从不同颗粒度来拆分，业务领域知识包括：</p>
<ul>
<li><strong>业务层面（更大颗粒度）</strong>：
<ul>
<li>投放；内容产品；商业化；（其实就是对应 GMV = DNU * LT * Arpu）</li>
</ul>
</li>
<li><strong>产品层面</strong>：
<ul>
<li>分发；基础体验；社区；搜索；</li>
</ul>
</li>
<li><strong>更小颗粒度</strong>：
<ul>
<li>分发：内容引入；内容分发；</li>
<li>变现：广告；会员；电商；直播；游戏；</li>
<li>搜索：召回；排序；相关性；</li>
</ul>
</li>
</ul>
<p>。。。还可以继续往下拆。正如数学上的分形一样：每个点都能继续往下细分，细分的每个点都是一个系统。</p>
<p>由于分工不同，研发所掌握的业务领域知识和PM在颗粒度、深度方面是不一样的，但大家在较粗的颗粒度、轮廓上是可以达成共识的。也就是能形成共同的语言和认知，后续在需求、规划交流上是可以更加高效、更有建设性的。</p>
<p><strong>例子</strong>：在搜索方向上，由于大家有了这样的共同语言，可以做到一部分需求是研发驱动的。即，研发会去和PM提需求，达成共识后，进行推进。</p>
<h3 id="如何获取业务领域知识呢">如何获取业务领域知识呢？</h3>
<ol>
<li>和业务领域专家（PM）长期、充分沟通；</li>
<li>多自行思考、串联；比如给自己提个问题：我能自行来推导出这个业务领域、系统吗？（粗粒度意义上的）</li>
<li>关注信息来源获取，包括书籍、公司内外的文章、文档；</li>
</ol>
<p>作为研发，如何检验自己的业务领域知识的掌握情况如何？最直接的体现就是，在工作中，尽可能利用这些知识来做判断，以及和其他同学做讨论。另外一个可行的方式是，写文档，然后分享出来。</p>
<p>关于业务理解这块，我们可以尝试用一些抽象的方式来概括：</p>
<ul>
<li><strong>公式建模</strong>；这种方式我发现经济学书籍里比较常用：寻找一堆变量因子，然后用一个公式、等式来建立联系，从而能看清楚因子之间如何变化；</li>
<li><strong>流程图</strong>；<br>
通过这样的方式，你会对自己所从事的业务更加清晰。当然，过于抽象也是有问题的，会丢失细节。所以我们也要谨防别过于形而上。</li>
</ul>
<h3 id="一些例子">一些例子：</h3>
<p><strong>公式的例子</strong>：<br>
<img src="https://mzhtech.github.io/post-images/1727255472783.png" alt="" loading="lazy"><br>
<strong>流程图的例子</strong>：</p>
<ul>
<li>电商转化：<br>
<img src="https://mzhtech.github.io/post-images/1727255581994.png" alt="" loading="lazy"></li>
</ul>
<h2 id="找到主线">找到主线</h2>
<p>无论是个人，还是团队，都应该找到自己在大业务中的角色和定位，制定好自己要交付的目标，或者说你想讲好的一个“故事”。这些目标往往也以职责、使命、原则出现。让这些长期目标指引着自己的主线，以免陷入一种多线作战、目标混乱的情况。这些主线目标往往来自于mentor、leader。如果不清晰的话，可以和其进行交流。</p>
<h3 id="一些例子-2">一些例子：</h3>
<ul>
<li><strong>业务</strong>：
<ul>
<li>小说业务的使命和愿景：
<ul>
<li>使命：让人人都能享受好故事，让好故事影响更多人</li>
<li>愿景：中国最大的故事创作与交流平台</li>
</ul>
</li>
</ul>
</li>
<li><strong>团队</strong>：
<ul>
<li>番茄小说服务端的职责：
<ul>
<li>业务迭代：保障业务功能迭代与交付；</li>
<li>服务保障：完善服务端基础建设；</li>
<li>技术反哺：基于数据、算法策略的技术驱动，帮助促进业务发展；</li>
</ul>
</li>
</ul>
</li>
<li><strong>个人</strong>：
<ul>
<li>XX方向/子方向的owner；</li>
<li>XX模块/项目的owner；</li>
</ul>
</li>
</ul>
<h2 id="实践">实践</h2>
<h3 id="紧贴业务">紧贴业务</h3>
<ul>
<li><strong>关注业务动向</strong>：需要更多地了解所参与的业务、子业务的未来发展规划，包括季度OKR、半年/一年规划等，并消化成自己对该业务的理解。可以多和PM进行沟通、了解；</li>
<li><strong>关注业务指标</strong>：从数据指标入手是有效地理解、紧贴业务的一个有效方法。需要了解业务发展的北极星指标，并关注各项需求是否有效地推动了这些指标的提升。需要构建比较强的数据驱动sense；</li>
<li><strong>关注业务痛点</strong>：业务的痛点，包括用户增长、商业变现、效率等。有些问题可能研发也确实没办法帮上忙，但有些问题是研发能解的，比如一些流程效率问题。往往要解决这类问题，在技术上并不是一个太难的事情，特别是在知道解法之后。这类事情的关键在于问题洞察、分析，并提供恰当的技术去解决，也是体现技术价值一个很重要的点；</li>
<li><strong>关注技术价值</strong>：研发除了做好交付之外，应该更多思考如何提供更多的价值。比如，了解业务规划之后，不应该仅仅停留在了解阶段，而应该思考如何做好对应的技术规划、建设。甚至于，可以做好一些技术能力建设，并和PM一起来探讨是否适合上线。还可以关注业务的卡点、瓶颈，思考技术如何用来解决这些问题；</li>
</ul>
<h3 id="一些关注技术价值的例子">一些关注技术价值的例子：</h3>
<ul>
<li>阅读器内划线算法，后来在段评、书摘场景落地；</li>
<li>全文搜索，提前做好技术储备，主动推动产品形态落地；</li>
<li>文本分类算法改善社区氛围；</li>
</ul>
<h2 id="数据驱动">数据驱动</h2>
<p>我们一直都在和数据打交道，我认为总共可以分三层：</p>
<ol>
<li><strong>构建功能</strong>。偏工程，进行在线数据交互、存储；</li>
<li><strong>构建策略</strong>。偏数仓，进行离线实时/异步清洗、聚合、排序，从数据指标中发现规律；</li>
<li><strong>构建模型</strong>。偏算法，利用模型来更精细化捕捉数据规律，从而更精准预测；</li>
</ol>
<p>每一层的递进意味着对于数据价值的利用的加深。作为常规的服务端团队来说，优先做好第一层；但为了可以更紧贴业务，应当更深入参与第二层；有了更强的数据利用能力之后，可以尝试切入第三层。</p>
<h2 id="问题建模">问题建模</h2>
<h3 id="第一性原理">第一性原理</h3>
<p>之前一直炒得很火的一个名词叫，第一性原理。摘抄自百科的意思是，回归事物的基本条件，将其进行解构分析，从而找到实现目标的最优路径。炒得很火的一个原因是埃隆·马斯克经常提起。</p>
<p>这个方法是关于如何解决问题的。我们工作中经常会遇到各种问题：技术问题、需求问题、流程问题、沟通协作问题等。大多数人的做法是，基于当前已有的信息，然后开始寻求解法，最后发现要不停打补丁，以致于解法越来越复杂，甚至无法解决。还有另外一个典型场景是，在一些技术协作链上，有些下游团队会接收到一些经由多手翻译的需求信息，这时，可能会有一些比较灵动的同学会问，“你的最原始需求是什么？”。</p>
<p>我们可以定义一个解决问题的流程：</p>
<ol>
<li><strong>定义问题</strong>。我们需要拆除掉表面所有繁复的东西，直接看到本质问题，然后进行抽象，这就是一个问题建模的过程。好的问题，是可以用简单的语言来表述的；如果不行，要么是定义问题的能力有问题，要么是隐含了多个问题。为了能更好地定义问题，我们需要拿到最纯净的信息，所以应该：</li>
<li>回归本质问题；</li>
<li>拆解子问题；</li>
<li>寻求可行解空间；</li>
<li>评估每个解的性价比；</li>
<li>解决问题；</li>
</ol>
<p>在以上的流程里，我觉得最应该重视解决的，是第一步——定义问题比解决问题更难。</p>
<p>我们可以来识别一些应用第一性原理的时机：</p>
<ul>
<li>当接收到的信息过于复杂时，试图找到本质问题；</li>
<li>当信息传递经过较多跳时，比如二手、三手、四手需求等；</li>
<li>当需求实现、技术方案讨论时间过长，并迟迟找不到解决方法时，尝试审视下最初的问题；</li>
<li>当技术债务产生的时间更久远时，我们要不要推倒重来；</li>
</ul>
<h3 id="一些例子-3">一些例子：</h3>
<p><strong>例子1</strong>：<br>
在日常工作中，我们经常需要评估技术方案。但往往很多同学都不注重定义问题，继而推导出最终的技术方案。所以，当我看到洋洋洒洒的方案之后，我会问，“这个方案要解决的问题是啥？难点在哪？” 只有我们知道问题在哪了，才能去寻找方案。</p>
<p><strong>例子2</strong>：<br>
最近团队同学在做一个多书名实验的事情。由于需求极其复杂，导致讨论了很长时间都没有结果。好不容易产生了一个多方都能达成共识的方案之后，刚加入的一位研发同学看到如此复杂的需求之后，产生了疑问，重新审视了原始的需求，然后提出了自己较为系统的解法。从我的角度来看，我是欣赏这个同学的做法的。他不会因为前人达成了结论就毫不怀疑，而是会从“头”去审视这个事情。其实这就是想从问题建模做起，重新找到最优解。</p>
<h2 id="系统建模">系统建模</h2>
<p>系统建模其实也可以理解为是一个问题归纳、抽象的过程。作为研发，接到的需求往往可能非常繁杂，充满了细节。这种情况下能进入开发环节么？当然可以，但你会被细节牵着走，执着于具体的细节应该怎么做，而忽视了做这个事情的目标，从而忽视了为了达成该目标而产生的可能的其他解决方案。套用编程方式的说法，这是一种“面向过程”的开发方法，是Bottom-Up的思维方式。</p>
<p>实际上，我们需要的是一种“面向领域”的开发方法，是一种自顶向下的思维方式。也就是说，我们想要解决的问题，是一个领域。具体操作上，可以这么做：</p>
<ol>
<li>先用一句话来概括，这是一个什么问题；</li>
<li>该问题的适用场景是啥，或者说有哪些约束条件；</li>
<li>该系统应该满足哪些原则；</li>
<li>基于原则，该问题可以拆解成哪些必要的阶段；</li>
<li>每个阶段是否支持优化、迭代，比如策略上的迭代等；</li>
</ol>
<p>通过以上几步，则已经构建了一个能解决该问题的系统了。接着，</p>
<ol start="6">
<li>把具体的需求套到这个系统里，看我们构建出来的系统是否能够套用到当前这个例子上。如果不能，是否可以继续归纳、抽象该系统，以能适配该例子；</li>
<li>想象后续可能发生的需求，该系统是否也能适用；</li>
</ol>
<p>事实上，关于1. 和2. ，科学家、算法工程师经常会形式化地用数学公式来表达。他们这么做其实就是在对问题建模，而我们工程研发，确实不用这么形式化。</p>
<p>系统建模还有另外一些好处，后续优化时，可以模块化地优化局部；和其他人员协作、沟通时，也能更聚焦该模块，减少信息耦合。当进行团队内工作分工时，也能按拆分的环节来进行划分。</p>
<h2 id="造思维的轮子">造思维的轮子</h2>
<p>除了工作中的实践，还有其他一些训练问题建模的方法。我自己比较常用的是——造思维的轮子。造轮子这个词，大家听得比较多，主要指的是在代码开发过程，实现了一些比较成熟的组件、库，而这种实现在实际的工程中其实没太必要。但造轮子有个好处是，相当于你亲自实现了一遍，从而你了解里面的原理，在使用的过程中也会更加熟悉；缺点就是，浪费了一些时间。</p>
<p>造思维的轮子，则相对省时间一些，毕竟不用真的去做一遍嘛，只要在头脑、纸上演绎一遍就好了。实际的做法是：假设你只获取到一些基本的信息，然后不借助更多的信息之下，尝试自己推演出整个系统。以广告系统作为例子，基本信息是：</p>
<ul>
<li>广告主会在广告系统提交广告素材；</li>
<li>广告系统要把素材展示给流量端的用户；</li>
<li>为了拓宽流量渠道，广告系统引入了流量主来作为流量渠道进行分发；</li>
<li>广告系统可以作为一个中介网络，作为其他广告系统的桥梁；</li>
</ul>
<p>要推演的信息是：</p>
<ul>
<li>应该如何决定把哪些广告展示给用户；</li>
<li>广告主如何定价等；</li>
<li>应该如何和广告主、流量主进行结算；</li>
<li>在中介网络场景下，该如何和其他广告系统进行结算；</li>
</ul>
<p>通过这样的思考方式，你会获得一个粗糙的广告系统机制，并能对其中一些环节有些初步的概念，例如竞拍、结算机制等。然后可以拿着这些信息去现实中对照“正确答案”。我认为这样的方式，会让你对该系统的认知更深刻一些，因为你经过了主动思考。</p>
<h2 id="穷尽解法">穷尽解法</h2>
<p>上面提到说，我们要在求解空间里找到最优解。我先说说我观察到的情况：我们的研发同学一般接到需求之后，就会靠直觉来设计技术方案，并且认为这就是最优解法。当然，我们会要求也做一些技术方案选型，但往往做得比较浅，也失去了对比的意义。最合适的方式是什么样子的呢？</p>
<p>我们知道，求解最暴力的方式就是暴力搜索，全搜一遍。精力有限，我们也不能这么做。但，我们至少要深入地思考几个可能的方案，最好能尽可能细致。可以遵循这样的方法：</p>
<ul>
<li>从问题出发，可能的解法有哪些；</li>
<li>对每一个解法依次展开，去思考可能面临的问题是什么，对于该子问题又有哪些新的解法；对于一些不重要的问题点，就不必展开了，以减少搜索空间；</li>
</ul>
<p>其实这就是一棵问题树的展开。可以认为，我们是在用启发式搜索的策略来找答案。启发式，体现在，我们对解法有些判断，只对最可行的点进行展开。</p>
<p>通过这种方式，你就获得了几个方案，然后就可以进行比较了。我上面提到的一些做法误区，本质上就是这颗问题树展开得不够深。</p>
<p>其实这也是我对“追求极致”的理解和实践。</p>
<h2 id="学习">学习</h2>
<h3 id="建立知识体系">建立知识体系</h3>
<p>建立知识体系的一个好处是，让自己更有系统地去学，也让自己学起来更有目标——知道自己要学啥、去哪学。</p>
<p>我们需要先确定自己想学习的东西，可以按照这种方式来寻找：</p>
<ul>
<li><strong>定位</strong>。结合自己当前工作所需要的技能、知识；未来的职业规划；自己的兴趣、抱负、精力投入、学习能力等，来制定自己的学习需求；</li>
<li><strong>建立体系</strong>。根据学习需求来制定你的能力模型和知识结构，要分门别类；</li>
<li><strong>按图索骥</strong>。根据每个类别，来寻求学习资料、实践机会等；</li>
</ul>
<h3 id="一些学习的方法">一些学习的方法：</h3>
<ul>
<li>
<p><strong>自底向上和自顶向下结合</strong></p>
<ul>
<li>自底向上：从基础知识、概念学起，逐步建立系统的知识体系。优点：扎实；缺点：周期长，较难看到落地效果，缺少反馈，难以坚持；</li>
<li>自顶向下：有两层含义：从了解顶层概念、场景、应用接触起，从具体的工作实践开始切入，以完成目标为导向；了解业界的最前沿实践。优点：对该领域能较快有全貌的认知，落地取得效果的周期比较可控；缺点：缺乏对细节的掌控；</li>
<li>例子：以搜索为例子，自底向上就是从零开始学习各种机器学习算法模型的知识、细节等，自顶向下则是从场景出发，拆解成召回、排序等，了解每个环节分别需要什么技术，然后直接尝试。两种方法都要结合，不同阶段需要调整两种方法的混合比例；</li>
</ul>
</li>
<li>
<p><strong>探索式学习</strong></p>
<ul>
<li>上面说要建立知识体系，这是建立在自己有一定了解，想进一步严肃学习、阅读的前提下。在没了解之前，建议可以散点式学习、了解，一方面是培养兴趣，一方面是，广撒点之后，可能慢慢就成呈现一张网，再对这张网进行系统化整理即可。一个可行的方法是：为了先培养兴趣，可以读一些较轻松的科普类兴致的读物，以帮助你大概窥探全貌；等你确认你真的对这个领域感兴趣了，再找严肃读物系统地进行阅读、学习；</li>
</ul>
</li>
<li>
<p><strong>主题式学习</strong></p>
<ul>
<li>阅读时不用追求把一整本书都看完。可以围绕某个主题，然后结合多本书一起阅读。</li>
</ul>
</li>
<li>
<p><strong>培养阅读兴趣</strong></p>
<ul>
<li>个人经验，把一本书从头到尾看完是一件很枯燥的事。所以，可以同时多看几本书来保持兴致，适时切换；</li>
</ul>
</li>
<li>
<p><strong>善用推荐引擎</strong></p>
<ul>
<li>当你在一些阅读平台上积累了较多的阅读习惯之后，这些平台的推荐引擎会根据你的兴趣来推荐相似主题的书。滚雪球似的，你会慢慢积累出一个还比较完备的书单，也就不会陷入书荒了，也能建立自己的阅读体系；</li>
</ul>
</li>
</ul>
<h3 id="了解其他职能">了解其他职能</h3>
<p>我们除了关注研发交付之外，也应该看看和我们工作联系最密切的同学——产品同学，并且了解下他们的工作方法。</p>
<h3 id="了解工作流程">了解工作流程</h3>
<p>先来看看一个产品的功能如何落地：</p>
<ol>
<li><strong>确定业务目标</strong>。如提升小说书城分发效率，比如可以拆解成提升人均书籍曝光量；</li>
<li><strong>设计产品形态</strong>；这块又可以拆成交互和视觉。可以把交互想象成，假设不考虑任何美观，产品的功能需要如何和用户进行交互，从而来满足用户的需求；视觉则是，进一步对交互进行细化、美化，不至于那么生硬；</li>
<li><strong>设计产品策略</strong>；通过上述的步骤，我们已经有了一个基础的产品功能，但在策略上还不一定是最高效的。还是以书城分发为例，应该如何将用户和书进行匹配推荐分发呢？这里就需要策略了。</li>
</ol>
<p>接着我们来看各角色和职能。上述的总体流程，再加上和各职能协作的流程（比如和研发、设计对需求细节、定排期等），就是一个产品经理的职责了。交互和视觉是由设计职能团队来负责，而由于产品经理需要和设计团队来沟通产品功能的需求，所以至少也要懂得比较粗粒度的交互设计。在策略这块，慢慢衍生出策略产品经理。</p>
<p>那在这些事情上面，研发应该对哪些环节有所了解会更有助于自己工作呢？产品策略这块，做算法的同学，天然就关注这块；工程同学了解一些也是可以的。视觉，更多地是涉及审美，不算是研发应该掌握的。而交互，应该是工程、算法同学都应该去了解的。</p>
<h3 id="提升产品sense">提升产品sense</h3>
<p>我们会经常听到一个词——产品sense，其实更多就是指交互这块。每个人每天都在和非常多的互联网产品/线下产品接触、使用，或多或少会积累一些感觉，例如，某个东西是否好用，某种功能的通用模式是怎样的，等等。这种感觉不用通过专门的培训、学习就能学会的。但现实中，确实有些人会更有产品sense一些。如何来强化这种sense呢？</p>
<p>还是训练，可以这么来训练：</p>
<ul>
<li>如果自己是普通用户/小白（意思是清空自己对于这个功能一清二楚的认知），自己对设计出来的产品功能是否满意，觉得是否合理；</li>
<li>如果不合理，你会认为怎么修正会更好；</li>
<li>你认为直观上是否能达到PM预期想达到的目标；为了达到该目标，目前的功能是否过于复杂，能否简化？</li>
<li>根据现有的交互，通过一些复杂的操作，有没有可能产生一些不符合预期的结果；</li>
<li>用户的真正需求是什么？该功能满足了么？</li>
</ul>
<p>平时也可以多留意一些自己常用的APP及功能，并思考一些问题，来做一些这方面的训练。以下列了一些我想到的例子。</p>
<ul>
<li>每个人都会听音乐，音乐应该按什么维度来收藏。为此，应该设计什么功能来满足需求。</li>
<li>照片应该怎么分类整理？</li>
<li>即时聊天工具要不要有已读功能？那为什么微信没有、飞书有？</li>
<li>飞书文档和word相比，你更喜欢哪个产品，为什么？</li>
<li>飞书的表情回复功能是必要的吗？解决了人们的哪些需求？</li>
</ul>
<h3 id="dogfooding">Dogfooding</h3>
<p>我们自己开发出来的产品，要更多地亲身去体验，从而去发现使用上的问题，包括交互体验、技术性能问题等。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Golang开发笔记]]></title>
        <id>https://mzhtech.github.io/post/golang-kai-fa-bi-ji/</id>
        <link href="https://mzhtech.github.io/post/golang-kai-fa-bi-ji/">
        </link>
        <updated>2024-09-25T08:29:20.000Z</updated>
        <content type="html"><![CDATA[<h1 id="一-前言">一、前言</h1>
<p>本文意在对 GoLang 面试题进行归纳总结，也欢迎读者进行评论或者留言分享面试题，希望读者看后能够具备“吊打面试官”的能力。本文中点到为止的知识点望读者可以根据关键词自行查漏补缺。</p>
<hr>
<h1 id="二-内容">二、内容</h1>
<h2 id="基础篇">基础篇</h2>
<ol>
<li>
<p><strong>与其他语言相比，使用 Go 有什么好处？</strong></p>
<ul>
<li>与其他作为学术实验开始的语言不同，Go 代码的设计是务实的。每个功能和语法决策都旨在让程序员的生活更轻松。</li>
<li>Golang 针对并发进行了优化，并且在规模上运行良好。</li>
<li>自动垃圾收集明显比 Java 或 Python 更有效，因为它与程序同时执行。</li>
</ul>
</li>
<li>
<p><strong>Go 程序中的包是什么？</strong></p>
<ul>
<li>包（pkg）是 Go 工作区中包含 Go 源文件或其他包的目录。源文件中的每个函数、变量和类型都存储在链接包中。每个 Go 源文件都属于一个包，该包在文件顶部使用以下命令声明：<pre><code class="language-go">package &lt;packagename&gt;
</code></pre>
</li>
<li>您可以使用以下方法导入和导出包以重用导出的函数或类型：<pre><code class="language-go">import &lt;packagename&gt;
</code></pre>
</li>
<li>Golang 的标准包是 fmt，其中包含格式化和打印功能，如 Println()。</li>
</ul>
</li>
<li>
<p><strong>Go 支持什么形式的类型转换？将整数转换为浮点数。</strong></p>
<ul>
<li>Go 支持显式类型转换以满足其严格的类型要求。<pre><code class="language-go">i := 55 // int
j := 67.8 // float64
sum := i + int(j) // j is converted to int
</code></pre>
</li>
</ul>
</li>
<li>
<p><strong>什么是 Goroutine？你如何停止它？</strong></p>
<ul>
<li>一个 Goroutine 是一个函数或方法执行同时旁边其他任何够程采用了特殊的 Goroutine 线程，这里叫做协程。协程比标准线程更轻量级，大多数 Golang 程序同时使用数千个 Goroutine。</li>
<li>要创建 Goroutine，请 go 在函数声明之前添加关键字。<pre><code class="language-go">go func(x, y, z)
</code></pre>
</li>
<li>您可以通过向 Goroutine 发送一个信号通道来停止它。Goroutines 只能在被告知检查时响应信号，因此您需要在逻辑位置（例如 for 循环顶部）包含检查。<pre><code class="language-go">package main

func main() {
    quit := make(chan bool)
    go func() {
        for {
            select {
            case &lt;-quit:
                return
            default:
                // ...
            }
        }
    }()
    // ...
    quit &lt;- true
}
</code></pre>
</li>
</ul>
</li>
<li>
<p><strong>如何在运行时检查变量类型？</strong></p>
<ul>
<li>类型开关（Type Switch）是在运行时检查变量类型的最佳方式。类型开关按类型而不是值来评估变量。每个 Switch 至少包含一个 case 用作条件语句，如果没有一个 case 为真，则执行 default。</li>
</ul>
</li>
<li>
<p><strong>Go 两个接口之间可以存在什么关系？</strong></p>
<ul>
<li>如果两个接口有相同的方法列表，那么他们就是等价的，可以相互赋值。</li>
<li>如果接口 A 的方法列表是接口 B 的方法列表的子集，那么接口 B 可以赋值给接口 A。接口查询是否成功，要在运行期才能够确定。</li>
</ul>
</li>
<li>
<p><strong>Go 当中同步锁有什么特点？作用是什么？</strong></p>
<ul>
<li>当一个 Goroutine（协程）获得了 Mutex 后，其他 Goroutine（协程）就只能乖乖的等待，除非该 Goroutine 释放了该 Mutex。RWMutex 在读锁占用的情况下，会阻止写，但不阻止读。RWMutex 在写锁占用情况下，会阻止任何其他 Goroutine（无论读和写）进来，整个锁相当于由该 Goroutine 独占。同步锁的作用是保证资源在使用时的独有性，不会因为并发而导致数据错乱，保证系统的稳定性。</li>
</ul>
</li>
<li>
<p><strong>Go 语言当中 Channel（通道）有什么特点，需要注意什么？</strong></p>
<ul>
<li>如果给一个 nil 的 channel 发送数据，会造成永远阻塞。</li>
<li>如果从一个 nil 的 channel 中接收数据，也会造成永久阻塞。</li>
<li>给一个已经关闭的 channel 发送数据，会引起 panic。</li>
<li>从一个已经关闭的 channel 接收数据，如果缓冲区中为空，则返回一个零值。</li>
</ul>
</li>
<li>
<p><strong>Go 语言当中 Channel 缓冲有什么特点？</strong></p>
<ul>
<li>无缓冲的 channel 是同步的，而有缓冲的 channel 是非同步的。</li>
</ul>
</li>
<li>
<p><strong>Go 语言中 cap 函数可以作用于哪些内容？</strong></p>
<ul>
<li>可以作用于的类型有：
<ul>
<li>array（数组）</li>
<li>slice（切片）</li>
<li>channel（通道）</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Go Convey 是什么？一般用来做什么？</strong></p>
<ul>
<li>goconvey 是一个支持 Golang 的单元测试框架。</li>
<li>go convey 能够自动监控文件修改并启动测试，并可以将测试结果实时输出到 Web 界面。</li>
<li>go convey 提供了丰富的断言简化测试用例的编写。</li>
</ul>
</li>
<li>
<p><strong>Go 语言当中 new 的作用是什么？</strong></p>
<ul>
<li>new 创建一个该类型的实例，并且返回指向该实例的指针。</li>
<li>new 函数是内建函数，函数定义：<pre><code class="language-go">func new(Type) *Type
</code></pre>
</li>
<li>使用 new 函数来分配空间。</li>
<li>传递给 new 函数的是一个类型，而不是一个值。</li>
<li>返回值是指向这个新分配的地址的指针。</li>
</ul>
</li>
<li>
<p><strong>Go 语言中 make 的作用是什么？</strong></p>
<ul>
<li>make 的作用是为：slice、map、chan 的初始化然后返回引用。</li>
<li>make 函数是内建函数，函数定义：<pre><code class="language-go">func make(Type, size IntegerType) Type
</code></pre>
</li>
<li>make（T， args）函数的目的和 new（T）不同，仅仅用于创建 slice、map、channel 而且返回类型是实例。</li>
</ul>
</li>
<li>
<p><strong>golang 中 make 和 new 的区别？</strong></p>
<ul>
<li><strong>共同点</strong>：
<ul>
<li>给变量分配内存。</li>
</ul>
</li>
<li><strong>不同点</strong>：
<ul>
<li>作用变量类型不同，new 给 string，int 和数组分配内存，make 给切片，map，channel 分配内存；</li>
<li>返回类型不一样，new 返回指向变量的指针，make 返回变量本身；</li>
<li>new 分配的空间被清零。make 分配空间后，会进行初始化；</li>
<li>分配的位置，在堆上还是在栈上？Go 语言会在两个地方给变量分配内存，虽然 Go 也是可以通过 new 来给变量分配内存，但是分配的这块内存，可能在堆上，也可能在栈上。从性能的角度出发，在栈上分配内存和在堆上分配内存，性能差异是非常大的。因此一个变量是在堆上分配内存，还是在栈上分配内存，是需要编译器经过逃逸分析才能得出结论。make 需要对对象进行初始化所以是在堆上。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Printf（），Sprintf（），FprintF（） 都是格式化输出，有什么不同？</strong></p>
<ul>
<li>虽然这三个函数，都是格式化输出，但是输出的目标不一样。
<ul>
<li>Printf（） 是标准输出，一般是屏幕，也可以重定向。</li>
<li>Sprintf（） 是把格式化字符串输出到指定的字符串中。</li>
<li>Fprintf（） 是把格式化字符串输出到文件中。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Go 语言当中数组和切片的区别是什么？</strong></p>
<ul>
<li><strong>数组</strong>：
<ul>
<li>数组固定长度。数组长度是数组类型的一部分，所以 [3]int 和 [4]int 是两种不同的数组类型。</li>
<li>数组需要指定大小，不指定也会根据初始化，自动推算出大小，大小不可改变。数组是通过值传递的。</li>
</ul>
</li>
<li><strong>切片</strong>：
<ul>
<li>切片可以改变长度。切片是轻量级的数据结构，三个属性，指针，长度，容量，不需要指定大小。</li>
<li>切片是地址传递（引用传递），可以通过数组来初始化，也可以通过内置函数 make() 来初始化，初始化的时候 len=cap，然后进行扩容。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Go 语言当中值传递和地址传递（引用传递）如何运用？有什么区别？举例说明</strong></p>
<ul>
<li>值传递只会把参数的值复制一份放进对应的函数，两个变量的地址不同，不可相互修改。</li>
<li>地址传递（引用传递）会将变量本身传入对应的函数，在函数中可以对该变量进行值内容的修改。</li>
</ul>
</li>
<li>
<p><strong>Go 语言当中数组和切片在传递的时候的区别是什么？</strong></p>
<ul>
<li>数组是值传递。</li>
<li>切片看上去像是引用传递，但其实是值传递。</li>
</ul>
</li>
<li>
<p><strong>Go 语言是如何实现切片扩容的？</strong></p>
<pre><code class="language-go">func main() {
    arr := make([]int, 0)
    for i := 0; i &lt; 2000; i++ {
        fmt.Println(&quot;len 为&quot;, len(arr), &quot;cap 为&quot;, cap(arr))
        arr = append(arr, i)
    }
}
</code></pre>
<ul>
<li>我们可以看下结果依次是 0,1,2,4,8,16,32,64,128,256,512,1024，但到了 1024 之后，就变成了 1024,1280,1696,2304 每次都是扩容了四分之一左右。</li>
</ul>
</li>
<li>
<p><strong>defer 的执行顺序是什么？defer 的作用和特点是什么？</strong></p>
<ul>
<li>defer 的作用是：
<ul>
<li>你只需要在调用普通函数或方法前加上关键字 defer，就完成了 defer 所需要的语法。当 defer 语句被执行时，跟在 defer 后面的函数会被延迟执行。直到包含该 defer 语句的函数执行完毕时，defer 后的函数才会被执行，不论包含 defer 语句的函数是通过 return 正常结束，还是由于 panic 导致的异常结束。你可以在一个函数中执行多条 defer 语句，它们的执行顺序与声明顺序相反。</li>
</ul>
</li>
<li><strong>defer 的常用场景</strong>：
<ul>
<li>defer 语句经常被用于处理成对的操作，如打开、关闭、连接、断开连接、加锁、释放锁。</li>
<li>通过 defer 机制，不论函数逻辑多复杂，都能保证在任何执行路径下，资源被释放。</li>
<li>释放资源的 defer 应该直接跟在请求资源的语句后。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Go 的 defer 底层数据结构？</strong></p>
<ul>
<li>每个 defer 语句都对应一个 _defer 实例，多个实例使用指针连接起来形成一个单连表，保存在 goroutine 数据结构中，每次插入 _defer 实例，均插入到链表的头部，函数结束再一次从头部取出，从而形成后进先出的效果。</li>
</ul>
</li>
<li>
<p><strong>Golang Slice 的底层实现？</strong></p>
<ul>
<li>切片是基于数组实现的，它的底层是数组，它自己本身非常小，可以理解为对底层数组的抽象。因为基于数组实现，所以它的底层的内存是连续分配的，效率非常高，还可以通过索引获得数据。</li>
<li>切片本身并不是动态数组或者数组指针。它内部实现的数据结构通过指针引用底层数组，设定相关属性将数据读写操作限定在指定的区域内。切片本身是一个只读对象，其工作机制类似数组指针的一种封装。</li>
<li>切片对象非常小，是因为它是只有 3 个字段的数据结构：
<ul>
<li>指向底层数组的指针</li>
<li>切片的长度</li>
<li>切片的容量</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Golang Slice 的扩容机制，有什么注意点？</strong></p>
<ul>
<li>Go 中切片扩容的策略是这样的：
<ul>
<li>首先判断，如果新申请容量大于 2 倍的旧容量，最终容量就是新申请的容量。</li>
<li>否则判断，如果旧切片的长度小于 1024，则最终容量就是旧容量的两倍。</li>
<li>否则判断，如果旧切片长度大于等于 1024，则最终容量从旧容量开始循环增加原来的 1/4，直到最终容量大于等于新申请的容量。</li>
<li>如果最终容量计算值溢出，则最终容量就是新申请容量。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>扩容前后的 Slice 是否相同？</strong></p>
<ul>
<li><strong>情况一</strong>：
<ul>
<li>原数组还有容量可以扩容（实际容量没有填充完），这种情况下，扩容以后的数组还是指向原来的数组，对一个切片的操作可能影响多个指针指向相同地址的 Slice。</li>
</ul>
</li>
<li><strong>情况二</strong>：
<ul>
<li>原来数组的容量已经达到了最大值，再想扩容，Go 默认会先开一片内存区域，把原来的值拷贝过来，然后再执行 append() 操作。这种情况丝毫不影响原数组。</li>
</ul>
</li>
<li>要复制一个 Slice，最好使用 Copy 函数。</li>
</ul>
</li>
<li>
<p><strong>Golang 的参数传递、引用类型</strong></p>
<ul>
<li>Go 语言中所有的传参都是值传递（传值），都是一个副本，一个拷贝。因为拷贝的内容有时候是非引用类型（int、string、struct 等这些），这样就在函数中就无法修改原内容数据；有的是引用类型（指针、map、slice、chan 等这些），这样就可以修改原内容数据。</li>
</ul>
</li>
<li>
<p><strong>Golang Map 底层实现</strong></p>
<ul>
<li>
<p>Golang 中 map 的底层实现是一个散列表，因此实现 map 的过程实际上就是实现散表的过程。在这个散列表中，主要出现的结构体有两个，一个叫 hmap（a header for a go map），一个叫 bmap（a bucket for a Go map，通常叫其 bucket）。</p>
</li>
<li>
<p>用链表来解决冲突，出现冲突时，不是每一个 key 都申请一个结构通过链表串起来，而是以 bmap 为最小粒度挂载，一个 bmap 可以放 8 个 kv。</p>
</li>
<li>
<p>在哈希函数的选择上，会在程序启动时，检测 cpu 是否支持 aes，如果支持，则使用 aes hash，否则使用 memhash。每个 map 的底层结构是 hmap，是有若干个结构为 bmap 的 bucket 组成的数组。每个 bucket 底层都采用链表结构。</p>
<pre><code class="language-go">type hmap struct {
    count     int                  // 元素个数
    flags     uint8
    B         uint8                // 扩容常量相关字段B是buckets数组的长度的对数 2^B
    noverflow uint16               // 溢出的bucket个数
    hash0     uint32               // hash seed
    buckets    unsafe.Pointer      // buckets 数组指针
    oldbuckets unsafe.Pointer      // 结构扩容的时候用于赋值的buckets数组
    nevacuate  uintptr             // 搬迁进度
    extra *mapextra                // 用于扩容的指针
}
</code></pre>
</li>
</ul>
</li>
<li>
<p><strong>Golang Map 如何扩容</strong></p>
<ol>
<li><strong>双倍扩容</strong>：扩容采取了一种称为“渐进式”的方式，原有的 key 并不会一次性搬迁完毕，每次最多只会搬迁 2 个 bucket。</li>
<li><strong>等量扩容</strong>：重新排列，极端情况下，重新排列也解决不了，map 存储就会蜕变成链表，性能大大降低，此时哈希因子 hash0 的设置，可以降低此类极端场景的发生。</li>
<li><strong>装载因子超过阈值</strong>，源码里定义的阈值是 6.5。</li>
<li><strong>overflow 的 bucket 数量过多</strong>，map 的 bucket 定位和 key 的定位高八位用于定位 bucket，低八位用于定位 key，快速试错后再进行完整对比。</li>
</ol>
</li>
<li>
<p><strong>Golang Map 查找</strong></p>
<ul>
<li>Go 语言中 map 采用的是哈希查找表，由一个 key 通过哈希函数得到哈希值，64 位系统中就生成一个 64bit 的哈希值，由这个哈希值将 key 对应存到不同的桶（bucket）中，当有多个哈希映射到相同的的桶中时，使用链表解决哈希冲突。</li>
<li>细节：key 经过 hash 后共 64 位，根据 hmap 中 B 的值，计算它到底要落在哪个桶时，桶的数量为 2^B，如 B=5，那么用 64 位最后 5 位表示第几号桶，在用 hash 值的高 8 位确定在 bucket 中的存储位置，当前 bmap 中的 bucket 未找到，则查询对应的 overflow bucket，对应位置有数据则对比完整的哈希值，确定是否是要查找的数据。如果当前 map 处于数据搬移状态，则优先从 oldbuckets 查找。</li>
</ul>
</li>
<li>
<p><strong>Go的原生map中删除元素，内存会自动释放吗？</strong></p>
<ul>
<li>如果删除的元素是值类型，如 int，float，bool，string 以及数组和 struct，map 的内存不会自动释放；</li>
<li>如果删除的元素是引用类型，如指针，slice，map，chan 等，map 的内存会自动释放，但释放的内存是子元素应用类型的内存占用；```markdown</li>
<li>细节：key 经过 hash 后共 64 位，根据 hmap 中 B 的值，计算它到底要落在哪个桶时，桶的数量为 2^B，如 B=5，那么用 64 位最后 5 位表示第几号桶，在用 hash 值的高 8 位确定在 bucket 中的存储位置，当前 bmap 中的 bucket 未找到，则查询对应的 overflow bucket，对应位置有数据则对比完整的哈希值，确定是否是要查找的数据。如果当前 map 处于数据搬移状态，则优先从 oldbuckets 查找。</li>
</ul>
</li>
<li>
<p><strong>Go 的原生 map 中删除元素，内存会自动释放吗？</strong></p>
<ul>
<li>如果删除的元素是值类型，如 int、float、bool、string 以及数组和 struct，map 的内存不会自动释放。</li>
<li>如果删除的元素是引用类型，如指针、slice、map、chan 等，map 的内存会自动释放，但释放的内存是子元素应用类型的内存占用。</li>
<li>将 map 设置为 nil 后，内存被回收。</li>
</ul>
</li>
<li>
<p><strong>slices 能作为 map 类型的 key 吗？</strong></p>
<ul>
<li>在 golang 规范中，可比较的类型都可以作为 map key。</li>
<li>不能作为 map key 的类型包括：
<ul>
<li>slices</li>
<li>maps</li>
<li>functions</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>介绍一下 Channel</strong></p>
<ul>
<li>Go 语言中，不通过共享内存来通信，而通过通信来实现内存共享。Go 的 CSP（Communicating Sequential Process）并发模型，中文可以叫做通信顺序进程，是通过 goroutine 和 channel 来实现的。</li>
<li>channel 收发遵循先进先出 FIFO 的原则。分为有缓冲区和无缓冲区，channel 中包括 buffer、sendx 和 recvx 收发的位置（ring buffer 记录实现）、sendq、recv。当 channel 因为缓冲区不足而阻塞了队列，则使用双向链表存储。</li>
</ul>
</li>
<li>
<p><strong>Channel 是线程安全的吗？</strong></p>
<ul>
<li>channel 是线程安全的，原因是 channel 内部实现了锁的机制。</li>
</ul>
</li>
<li>
<p><strong>Channel 的 ring buffer 实现</strong></p>
<ul>
<li>channel 中使用了 ring buffer（环形缓冲区）来缓存写入的数据。ring buffer 有很多好处，而且非常适合用来实现 FIFO 式的固定长度队列。</li>
</ul>
</li>
<li>
<p><strong>当 Channel 通道被 close 后，读会带来什么问题？</strong></p>
<ul>
<li>读取没问题，但是写入就会有问题。</li>
</ul>
<pre><code class="language-go">package main

import (&quot;fmt&quot;)

func main() {
    ch := make(chan int, 2) // 向通道发送数据
    ch &lt;- 1
    ch &lt;- 2 // 关闭通道
    close(ch) // 安全地从通道读取数据
    val, ok := &lt;-ch
    fmt.Println(val, ok) // 输出: 1 true
    val, ok = &lt;-ch
    fmt.Println(val, ok) // 输出: 2 true
    // 当通道中没有数据时，从已关闭的通道读取
    val, ok = &lt;-ch
    fmt.Println(val, ok) // 输出: 0 false
    // 再次尝试向已关闭的通道发送数据将导致 panic
    defer func() {
        if r := recover(); r != nil {
            fmt.Println(&quot;Recovered from panic:&quot;, r)
        }
    }()
    ch &lt;- 3 // 这将引发 panic
}
</code></pre>
</li>
<li>
<p><strong>for range 的时候它的地址会发生变化么？</strong></p>
<ul>
<li>在 <code>for a,b := range c {}</code> 遍历中，a 和 b 在内存中只会存在一份，即之后每次循环时遍历到的数据都是以值覆盖的方式赋给 a 和 b，a，b 的内存地址始终不变。由于有这个特性，for 循环里面如果开协程，不要直接把 a 或者 b 的地址传给协程。解决办法：在每次循环时，创建一个临时变量。</li>
</ul>
</li>
<li>
<p><strong>golang 中解析 tag 是怎么实现的？反射原理是什么？</strong></p>
<ul>
<li>Go 中解析的 tag 是通过反射实现的，反射是指计算机程序在运行时（Run time）可以访问、检测和修改它本身状态或行为的一种能力。反射将接口变量转换成反射对象 Type 和 Value；反射可以通过反射对象 Value 还原成原先的接口变量；反射可以用来修改一个变量的值，前提是这个值可以被修改；tag 是啥：结构体支持标记，name string json:name-field 就是 json:name-field 这部分，gorm json yaml gRPC protobuf gin.Bind() 都是通过反射来实现的。</li>
</ul>
<pre><code class="language-go">type User struct {
    name string `json:name-field`
    age  int
}

func main() {
    user := &amp;User{&quot;John Doe The Fourth&quot;, 20}

    field, ok := reflect.TypeOf(user).Elem().FieldByName(&quot;name&quot;)
    if !ok {
        panic(&quot;Field not found&quot;)
    }
    fmt.Println(getStructTag(field))
}

func getStructTag(f reflect.StructField) string {
    return string(f.Tag)
}
</code></pre>
</li>
<li>
<p><strong>调用函数传入结构体时，应该传值还是指针？</strong></p>
<ul>
<li>Go 的函数参数传递都是值传递。所谓值传递：指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。参数传递还有引用传递，所谓引用传递是指在调用函数时将实际参数的地址传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。因为 Go 里面的 map，slice，chan 是引用类型。变量区分值类型和引用类型。</li>
</ul>
</li>
<li>
<p><strong>讲讲 Go 的 select 底层数据结构和一些特性？</strong></p>
<ul>
<li>
<p>Go 的 select 为 golang 提供了多路 IO 复用机制，和其他 IO 复用一样，用于检测是否有读写事件是否 ready。linux 的系统 IO 模型有 select，poll，epoll，go 的 select 和 linux 系统 select 非常相似。</p>
</li>
<li>
<p>select 结构组成主要是由 case 语句和执行的函数组成，select 实现的多路复用是：每个线程或者进程都先到注册和接受的 channel（装置）注册，然后阻塞，然后只有一个线程在运输，当注册的线程和进程准备好数据后，装置会根据注册的信息得到相应的数据。</p>
</li>
<li>
<p><strong>select 的特性</strong>：</p>
<ul>
<li>select 操作至少要有一个 case 语句，出现读写 nil 的 channel 该分支会忽略，在 nil 的 channel 上操作则会报错。</li>
<li>select 仅支持管道，而且是单协程操作。</li>
<li>每个 case 语句仅能处理一个管道，要么读要么写。</li>
<li>多个 case 语句的执行顺序是随机的。</li>
<li>存在 default 语句，select 将不会阻塞，但是存在 default 会影响性能。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>能介绍下 rune 类型吗？</strong></p>
<ul>
<li>相当于 int32，golang 中的字符串底层实现是通过 byte 数组的，中文字符在 unicode 下占 2 个字节，在 utf-8 编码下占 3 个字节，而 golang 默认编码正好是 utf-8。byte 等同于 int8，常用来处理 ascii 字符。rune 等同于 int32，常用来处理 unicode 或 utf-8 字符。</li>
</ul>
</li>
<li>
<p><strong>context 结构是什么样的？context 使用场景和用途？</strong></p>
<ul>
<li>
<p>Context 通常被称为上下文，在 go 中，理解为 goroutine 的运行状态、现场，存在上下层 goroutine context 的传递，上层 goroutine 会把 context 传递给下层 goroutine。</p>
</li>
<li>
<p>Go 的 Context 的数据结构包含 Deadline，Done，Err，Value，Deadline 方法返回一个 time.Time，表示当前 Context 应该结束的时间，ok 则表示有结束时间，Done 方法当 Context 被取消或者超时时候返回的一个 close 的 channel，告诉给 context 相关的函数要停止当前工作然后返回了，Err 表示 context 被取消的原因，Value 方法表示 context 实现共享数据存储的地方，是协程安全的。</p>
</li>
<li>
<p><strong>主要应用场景</strong>：</p>
<ul>
<li>上下文控制；</li>
<li>多个 goroutine 之间的数据交互等；</li>
<li>超时控制：到某个时间点超时，过多久超时。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Go 多返回值怎么实现的？</strong></p>
<ul>
<li>Go 传参和返回值是通过 FP + offset 实现，并且存储在调用函数的栈帧中。FP 栈底寄存器，指向一个函数栈的顶部；PC 程序计数器，指向下一条执行指令；SB 指向静态数据的基指针，全局符号；SP 栈顶寄存器。</li>
</ul>
</li>
<li>
<p><strong>Go 语言中不同的类型如何比较是否相等？</strong></p>
<ul>
<li>像 string，int，float interface 等可以通过 reflect.DeepEqual 和等于号进行比较，像 slice，struct，map 则一般使用 reflect.DeepEqual 来检测是否相等。</li>
</ul>
</li>
<li>
<p><strong>Go 中 init 函数的特征？</strong></p>
<ul>
<li>一个包下可以有多个 init 函数，每个文件也可以有多个 init 函数。多个 init 函数按照它们的文件名顺序逐个初始化。应用初始化时初始化工作的顺序是，从被导入的最深层包开始进行初始化，层层递出最后到 main 包。不管包被导入多少次，包内的 init 函数只会执行一次。但包级别变量的初始化先于包内 init 函数的执行。</li>
</ul>
</li>
<li>
<p><strong>Go 中 uintptr 和 unsafe.Pointer 的区别？</strong></p>
<ul>
<li>unsafe.Pointer 是通用指针类型，它不能参与计算，任何类型的指针都可以转化成 unsafe.Pointer，unsafe.Pointer 可以转化成任何类型的指针，uintptr 可以转换为 unsafe.Pointer，unsafe.Pointer 可以转换为 uintptr。uintptr 是指针运算的工具，但是它不能持有指针对象（意思就是它跟指针对象不能互相转换），unsafe.Pointer 是指针对象进行运算（也就是 uintptr）的桥梁。</li>
</ul>
</li>
<li>
<p><strong>深拷贝和浅拷贝</strong></p>
<ul>
<li>拷贝最简单的一种形式如下：<pre><code class="language-go">a := 648
b := a //把a 拷贝给 b
</code></pre>
</li>
<li>深浅拷贝也和类型有关。</li>
</ul>
</li>
<li>
<p><strong>如果 for range 同时添加数据， for range 会无限执行吗？</strong></p>
<ul>
<li>不会，在执行 for range 的时候实际遍历的是变量的副本，所以改变遍历的变量是不会有影响的。</li>
</ul>
</li>
<li>
<p><strong>单引号，双引号，反引号的区别？</strong></p>
<ul>
<li>单引号，表示 byte 类型或 rune 类型，对应 uint8 和 int32 类型，默认是 rune 类型。byte 用来强调数据是 raw data，而不是数字；而 rune 用来表示 Unicode 的 code point。</li>
<li>双引号，是字符串，实际上是字符数组。可以用索引号访问某字节，也可以用 len() 函数来获取字符串所占的字节长度。</li>
<li>反引号，表示字符串字面量，但不支持任何转义序列。字面量 raw literal string 的意思是，你定义时写的啥样，它就啥样，你有换行，它就换行。你写转义字符，它也就展示转义字符。</li>
</ul>
</li>
<li>
<p><strong>什么是数据溢出？</strong></p>
<ul>
<li>在使用数字类型时如果数据达到最大值，则接下来的数据将会溢出，如 uint 溢出后会从 0 开始， int 溢出后会变为负数。</li>
</ul>
<pre><code class="language-go">package main

import (
    &quot;fmt&quot;
    &quot;math&quot;
)

func main() {
    var n int8 = math.MaxInt8
    var m uint8 = math.MaxUint8

    n += 2
    m += 1

    fmt.Println(n) // -127
    fmt.Println(m) // 0
}
</code></pre>
<ul>
<li><strong>如何避免？</strong>
<ul>
<li>正数优先使用 uint, 范围更大。</li>
<li>添加判断代码判断是否溢出。</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h1 id="并发篇">并发篇</h1>
<h2 id="1-mutex-几种状态">1. Mutex 几种状态</h2>
<ul>
<li><strong>mutexLocked</strong> — 表示互斥锁的锁定状态；</li>
<li><strong>mutexWoken</strong> — 表示从正常模式被唤醒；</li>
<li><strong>mutexStarving</strong> — 当前的互斥锁进入饥饿状态；</li>
<li><strong>waitersCount</strong> — 当前互斥锁上等待的 Goroutine 个数；</li>
</ul>
<h2 id="2-mutex-正常模式和饥饿模式">2. Mutex 正常模式和饥饿模式</h2>
<ul>
<li>
<p><strong>正常模式（非公平锁）</strong><br>
正常模式下，所有等待锁的 goroutine 按照 FIFO（先进先出）顺序等待。唤醒的 goroutine 不会直接拥有锁，而是会和新请求 goroutine 竞争锁。新请求的 goroutine 更容易抢占：因为它正在 CPU 上执行，所以刚刚唤醒的 goroutine 有很大可能在锁竞争中失败。在这种情况下，这个被唤醒的 goroutine 会加入到等待队列的前面。</p>
</li>
<li>
<p><strong>饥饿模式（公平锁）</strong><br>
为了解决等待 goroutine 队列的长尾问题，在饥饿模式下，直接由 unlock 把锁交给等待队列中排在第一位的 goroutine（队头），同时，饥饿模式下，新进来的 goroutine 不会参与抢锁也不会进入自旋状态，会直接进入等待队列的尾部。这样很好地解决了老的 goroutine 一直抢不到锁的场景。<br>
饥饿模式的触发条件：当一个 goroutine 等待锁时间超过 1 毫秒时，或者当前队列只剩下一个 goroutine 的时候，Mutex 切换到饥饿模式。<br>
对于两种模式，正常模式下的性能是最好的，goroutine 可以连续多次获取锁，饥饿模式解决了取锁公平的问题，但是性能会下降，这其实是性能和公平的一个平衡模式。</p>
</li>
</ul>
<h2 id="3-mutex-允许自旋的条件">3. Mutex 允许自旋的条件</h2>
<ul>
<li>锁已被占用，并且锁不处于饥饿模式。</li>
<li>积累的自旋次数小于最大自旋次数（active_spin=4）。</li>
<li>CPU 核数大于 1。</li>
<li>有空闲的 P。</li>
<li>当前 Goroutine 所挂载的 P 下，本地待运行队列为空。<br>
PS：这里补充一下 GMP 模型。</li>
</ul>
<h2 id="4-rwmutex-实现">4. RWMutex 实现</h2>
<p>通过记录 <code>readerCount</code> 读锁的数量来进行控制，当有一个写锁的时候，会将读锁数量设置为负数 <code>1&lt;&lt;30</code>。目的是让新进入的读锁等待之前的写锁释放通知读锁。同样的，当有写锁进行抢占时，也会等待之前的读锁都释放完毕，才会开始进行后续的操作。而等写锁释放完之后，会将值重新加上 <code>1&lt;&lt;30</code>，并通知刚才新进入的读锁（<code>rw.readerSem</code>），两者互相限制。</p>
<h2 id="5-rwmutex-注意事项">5. RWMutex 注意事项</h2>
<ul>
<li>RWMutex 是单写多读锁，该锁可以加多个读锁或者一个写锁。</li>
<li>读锁占用的情况下会阻止写，不会阻止读，多个 Goroutine 可以同时获取读锁。</li>
<li>写锁会阻止其他 Goroutine（无论读和写）进来，整个锁由该 Goroutine 独占。</li>
<li>适用于读多写少的场景。</li>
<li>RWMutex 类型变量的零值是一个未锁定状态的互斥锁。</li>
<li>RWMutex 在首次被使用之后就不能再被拷贝。</li>
<li>RWMutex 的读锁或写锁在未锁定状态，解锁操作都会引发 panic。</li>
<li>RWMutex 的一个写锁去锁定临界区的共享资源，如果临界区的共享资源已被（读锁或写锁）锁定，这个写锁操作的 goroutine 将被阻塞直到解锁。</li>
<li>RWMutex 的读锁不要用于递归调用，比较容易产生死锁。</li>
<li>RWMutex 的锁定状态与特定的 goroutine 没有关联。一个 goroutine 可以 RLock（Lock），另一个 goroutine 可以 RUnlock（Unlock）。</li>
<li>写锁被解锁后，所有因操作锁定读锁而被阻塞的 goroutine 会被唤醒，并都可以成功锁定读锁。</li>
<li>读锁被解锁后，在没有被其他读锁锁定的前提下，所有因操作锁定写锁而被阻塞的 Goroutine，其中等待时间最长的一个 Goroutine 会被唤醒。</li>
</ul>
<h2 id="6-cond-是什么">6. Cond 是什么</h2>
<p>Cond 实现了一种条件变量，可以用于多个 Reader 等待共享资源 ready 的场景（如果只有一读一写，一个锁或者 channel 就搞定了），每个 Cond 都会关联一个 Lock（*sync.Mutex or *sync.RWMutex），当修改条件或者调用 Wait 方法时，必须加锁，保护 condition。</p>
<h2 id="7-broadcast-和-signal-区别">7. Broadcast 和 Signal 区别</h2>
<ul>
<li>
<p>*<em>func (c <em>Cond) Broadcast()</em></em><br>
Broadcast 会唤醒所有等待 c 的 goroutine。调用 Broadcast 的时候，可以加锁，也可以不加锁。</p>
</li>
<li>
<p>*<em>func (c <em>Cond) Signal()</em></em><br>
Signal 只唤醒 1 个等待 c 的 goroutine。调用 Signal 的时候，可以加锁，也可以不加锁。</p>
</li>
</ul>
<h2 id="8-cond-中-wait-使用">8. Cond 中 Wait 使用</h2>
<ul>
<li>*<em>func (c <em>Cond) Wait()</em></em><br>
Wait() 会自动释放 c.L 锁，并挂起调用者的 goroutine。之后恢复执行，Wait() 会在返回时对 c.L 加锁。<br>
除非被 Signal 或者 Broadcast 唤醒，否则 Wait() 不会返回。<br>
由于 Wait() 第一次恢复时，C.L 并没有加锁，所以当 Wait 返回时，调用者通常并不能假设条件为真。取而代之的是，调用者应该在循环中调用 Wait。（简单来说，只要想使用 condition，就必须加锁。）</li>
</ul>
<h2 id="9-waitgroup-用法">9. WaitGroup 用法</h2>
<p>一个 WaitGroup 对象可以等待一组协程结束。<br>
使用方法是：</p>
<ol>
<li>main 协程通过调用 <code>wg.Add(delta int)</code> 设置 worker 协程的个数，然后创建 worker 协程；</li>
<li>worker 协程执行结束以后，都要调用 <code>wg.Done()</code>；</li>
<li>main 协程调用 <code>wg.Wait()</code> 且被 block，直到所有 worker 协程全部执行结束后返回。</li>
</ol>
<h2 id="10-waitgroup-实现原理">10. WaitGroup 实现原理</h2>
<ul>
<li>WaitGroup 主要维护了 2 个计数器，一个是请求计数器 v，一个是等待计数器 w，二者组成一个 64bit 的值，请求计数器占高 32bit，等待计数器占低 32bit。</li>
<li>每次 Add 执行，请求计数器 v 加 1，Done 方法执行，等待计数器减 1，v 为 0 时通过信号量唤醒 Wait()。</li>
</ul>
<h2 id="11-什么是-synconce">11. 什么是 sync.Once</h2>
<ul>
<li>Once 可以用来执行且仅仅执行一次动作，常常用于单例对象的初始化场景。</li>
<li>Once 常常用来初始化单例资源，或者并发访问只需初始化一次的共享资源，或者在测试的时候初始化一次测试资源。</li>
<li>sync.Once 只暴露了一个方法 Do，你可以多次调用 Do 方法，但是只有第一次调用 Do 方法时 f 参数才会执行，这里的 f 是一个无参数无返回值的函数。</li>
</ul>
<h2 id="12-什么操作叫做原子操作">12. 什么操作叫做原子操作</h2>
<p>原子操作即是在程序进行过程中不能被中断的操作，针对某个值的原子操作在进行的过程中，CPU 绝不会再去进行其他的针对该值的操作。为了实现这样的严谨性，原子操作仅会由一个独立的 CPU 指令代表和完成。原子操作是无锁的，常常直接通过 CPU 指令直接实现。事实上，其它同步技术的实现常常依赖于原子操作。</p>
<h2 id="13-原子操作和锁的区别">13. 原子操作和锁的区别</h2>
<p>原子操作由底层硬件支持，而锁则由操作系统的调度器实现。锁应当用来保护一段逻辑，对于一个变量更新的保护。原子操作通常执行上会更有效率，并且更能利用计算机多核的优势，如果要更新的是一个复合对象，则应当使用 <code>atomic.Value</code> 封装好的实现。</p>
<h2 id="14-什么是-cas">14. 什么是 CAS</h2>
<p>CAS 的全称为 Compare And Swap，直译就是比较交换。是一条 CPU 的原子指令，其作用是让 CPU 先进行比较两个值是否相等，然后原子地更新某个位置的值，其实现方式是给予硬件平台的汇编指令，在 intel 的 CPU 中，使用的 <code>cmpxchg</code> 指令，就是说 CAS 是靠硬件实现的，从而在硬件层面提升效率。<br>
简述过程是这样：<br>
假设包含 3 个参数内存位置（V）、预期原值（A）和新值（B）。V 表示要更新变量的值，E 表示预期值，N 表示新值。仅当 V 值等于 E 值时，才会将 V 的值设为 N，如果 V 值和 E 值不同，则说明已经有其他线程在做更新，则当前线程什么都不做，最后 CAS 返回当前 V 的真实值。CAS 操作时抱着乐观的态度进行的，它总是认为自己可以成功完成操作。基于这样的原理，CAS 操作即使没有锁，也可以发现其他线程对于当前线程的干扰。</p>
<h2 id="15-syncpool-有什么用">15. sync.Pool 有什么用</h2>
<p>对于很多需要重复分配、回收内存的地方，<code>sync.Pool</code> 是一个很好的选择。频繁地分配、回收内存会给 GC 带来一定的负担，严重的时候会引起 CPU 的毛刺。而 <code>sync.Pool</code> 可以将暂时不用的对象缓存起来，待下次需要的时候直接使用，不用再次经过内存分配，复用对象的内存，减轻 GC 的压力，提升系统的性能。</p>
<h2 id="16-go-语言的并发机制以及它所使用的-csp-并发模型">16. Go 语言的并发机制以及它所使用的 CSP 并发模型</h2>
<p>CSP 模型是上个世纪七十年代提出的，不同于传统的多线程通过共享内存来通信，CSP 讲究的是“以通信的方式来共享内存”。用于描述两个独立的并发实体通过共享的通讯 channel（管道）进行通信的并发模型。CSP 中 channel 是第一类对象，它不关注发送消息的实体，而关注于发送消息时使用的 channel。<br>
Golang 中 channel 是被单独创建并且可以在进程之间传递，它的通信模式类似于 boss-worker 模式的，一个实体通过将消息发送到 channel 中，然后又监听这个 channel 的实体处理，两个实体之间是匿名的，这个就实现实体中间的解耦，其中 channel 是同步的，一个消息被发送到 channel 中，最终是一定要被另外的实体消费掉的，在实现原理上其实类似一个阻塞的消息队列。</p>
<h2 id="17-怎么限制-goroutine-的数量">17. 怎么限制 Goroutine 的数量</h2>
<pre><code class="language-go">package main

import (
    &quot;fmt&quot;
    &quot;runtime&quot;
    &quot;sync&quot;
    &quot;time&quot;
)

// Pool Goroutine Pool
type Pool struct {
    queue chan int
    wg    *sync.WaitGroup
}

// New 新建一个协程池
func NewPool(size int) *Pool {
    if size &lt;= 0 {
        size = 1
    }
    return &amp;Pool{
        queue: make(chan int, size),
        wg:    &amp;sync.WaitGroup{},
    }
}

// Add 新增一个执行
func (p *Pool) Add(delta int) {
    // delta为正数就添加
    for i := 0; i &lt; delta; i++ {
        p.queue &lt;- 1
    }
    // delta为负数就减少
    for i := 0; i &gt; delta; i-- {
        &lt;-p.queue
    }
    p.wg.Add(delta)
}

// Done 执行完成减一
func (p *Pool) Done() {
    &lt;-p.queue
    p.wg.Done()
}

// Wait 等待 Goroutine 执行完毕
func (p *Pool) Wait() {
    p.wg.Wait()
}

func main() {
    // 这里限制 5 个并发
    pool := NewPool(5)
    fmt.Println(&quot;the NumGoroutine begin is:&quot;, runtime.NumGoroutine())
    for i := 0; i &lt; 20; i++ {
        pool.Add(1)
        go func(i int) {
            time.Sleep(time.Second)
            fmt.Println(&quot;the NumGoroutine continue is:&quot;, runtime.NumGoroutine())
            pool.Done()
        }(i)
    }
    pool.Wait()
    fmt.Println(&quot;the NumGoroutine done is:&quot;, runtime.NumGoroutine())
}
</code></pre>
<p>其中，Go 的 GOMAXPROCS 默认值已经设置为 CPU 的核数，这里允许我们的 Go 程序充分使用机器的每一个 CPU，最大程度的提高我们程序的并发性能。<code>runtime.NumGoroutine</code> 函数在被调用后，会返回系统中的处于特定状态的 Goroutine 的数量。这里的特指是指 Grunnable、Gruning、Gsyscall、Gwaition。处于这些状态的 Goroutine 即被看做是活跃的或者说正在被调度。</p>
<h1 id="运行时">运行时</h1>
<h2 id="1-goroutine-定义">1. Goroutine 定义</h2>
<p>Golang 在语言级别支持协程，称之为 Goroutine。Golang 标准库提供的所有系统调用操作（包括所有的同步 I/O 操作），都会出让 CPU 给其他 Goroutine。这让 Goroutine 的切换管理不依赖于系统的线程和进程，也不依赖于 CPU 的核心数量，而是交给 Golang 的运行时统一调度。</p>
<h2 id="2-gmp-指的是什么">2. GMP 指的是什么</h2>
<ul>
<li><strong>G（Goroutine）</strong>：我们所说的协程，为用户级的轻量级线程，每个 Goroutine 对象中的 <code>sched</code> 保存着其上下文信息。</li>
<li><strong>M（Machine）</strong>：对内核级线程的封装，数量对应真实的 CPU 数（真正干活的对象）。</li>
<li><strong>P（Processor）</strong>：即为 G 和 M 的调度对象，用来调度 G 和 M 之间的关联关系，其数量可通过 <code>GOMAXPROCS()</code> 来设置，默认为核心数。</li>
</ul>
<h2 id="3-10-之前-gm-调度模型">3. 1.0 之前 GM 调度模型</h2>
<p>调度器把 G 都分配到 M 上，不同的 G 在不同的 M 并发运行时，都需要向系统申请资源，比如堆栈内存等，因为资源是全局的，就会因为资源竞争造成很多性能损耗。为了解决这一问题，Go 从 1.1 版本引入，在运行时系统的时候加入 P 对象，让 P 去管理这个 G 对象，M 想要运行 G，必须绑定 P，才能运行 P 所管理的 G。</p>
<h3 id="gm-调度存在的问题">GM 调度存在的问题：</h3>
<ul>
<li>单一全局互斥锁（<code>Sched.Lock</code>）和集中状态存储。</li>
<li>Goroutine 传递问题（M 经常在 M 之间传递“可运行”的 goroutine）。</li>
<li>每个 M 做内存缓存，导致内存占用过高，数据局部性较差。</li>
<li>频繁 syscall 调用，导致严重的线程阻塞/解锁，加剧额外的性能损耗。</li>
</ul>
<h2 id="4-gmp-调度流程">4. GMP 调度流程</h2>
<ul>
<li>每个 P 有个局部队列，局部队列保存待执行的 goroutine，当 M 绑定的 P 的局部队列已经满了之后就会把 goroutine 放到全局队列。</li>
<li>每个 P 和一个 M 绑定，M 是真正的执行 P 中 goroutine 的实体，M 从绑定的 P 中的局部队列获取 G 来执行。</li>
<li>当 M 绑定的 P 的局部队列为空时，M 会从全局队列获取到本地队列来执行 G，当从全局队列中没有获取到可执行的 G 时，M 会从其他 P 的局部队列中偷取 G 来执行，这种从其他 P 偷的方式称为 work stealing。</li>
<li>当 G 因系统调用（syscall）阻塞时会阻塞 M，此时 P 会和 M 解绑即 handoff，并寻找新的 idle 的 M，若没有 idle 的 M 就会新建一个 M。</li>
<li>当 G 因 channel 或者 network I/O 阻塞时，不会阻塞 M，M 会寻找其他 runnable 的 G；当阻塞的 G 恢复后会重新进入 runnable 进入 P 队列等待执行。</li>
</ul>
<h2 id="5-gmp-中-work-stealing-机制">5. GMP 中 work stealing 机制</h2>
<p>获取 P 本地队列，当从绑定 P 本地 runq 上找不到可执行的 G，尝试从全局链表中拿，再拿不到从 netpoll 和事件池里拿，最后会从别的 P 里偷任务。P 此时去唤醒一个 M。P 继续执行其它的程序。M 寻找是否有空闲的 P，如果有则将该 G 对象移动到它本身。接下来 M 执行一个调度循环（调用 G 对象 -&gt; 执行 -&gt; 清理线程 → 继续找新的 Goroutine 执行）。</p>
<h2 id="6-gmp-中-hand-off-机制">6. GMP 中 hand off 机制</h2>
<p>当本线程 M 因为 G 进行的系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的 M 执行。<br>
细节：当发生上下文切换时，需要对执行现场进行保护，以便下次被调度执行时进行现场恢复。Go 调度器 M 的栈保存在 G 对象上，只需要将 M 所需要的寄存器（SP、PC 等）保存到 G 对象上就可以实现现场保护。当这些寄存器数据被保护起来，就随时可以做上下文切换了，在中断之前把现场保存起来。如果此时 G 任务还没有执行完，M 可以将任务重新丢到 P 的任务队列，等待下一次被调度执行。当再次被调度执行时，M 通过访问 G 的 <code>vdsoSP</code>、<code>vdsoPC</code> 寄存器进行现场恢复（从上次中断位置继续执行）。</p>
<h2 id="7-协作式的抢占式调度">7. 协作式的抢占式调度</h2>
<p>在 1.14 版本之前，程序只能依靠 Goroutine 主动让出 CPU 资源才能触发调度。<br>
这种方式存在的问题有：</p>
<ul>
<li>某些 Goroutine 可以长时间占用线程，造成其它 Goroutine 的饥饿。</li>
<li>垃圾回收需要暂停整个程序（Stop-the-world，STW），最长可能需要几分钟的时间，导致整个程序无法工作。</li>
</ul>
<h2 id="8-基于信号的抢占式调度">8. 基于信号的抢占式调度</h2>
<p>在任何情况下，Go 运行时并行执行（注意，不是并发）的 goroutines 数量是小于等于 P 的数量的。为了提高系统的性能，P 的数量肯定不是越小越好，所以官方默认值就是 CPU 的核心数，设置的过小的话，如果一个持有 P 的 M，由于 P 当前执行的 G 调用了 syscall 而导致 M 被阻塞，那么此时关键点：Go 的调度器是迟钝的，它很可能什么都没做，直到 M 阻塞了相当长时间以后，才会发现有一个 P/M 被 syscall 阻塞了。然后，才会用空闲的 M 来抢这个 P。通过 sysmon 监控实现的抢占式调度，最快在 20us，最慢在 10-20ms 才会发现有一个 M 持有 P 并阻塞了。操作系统在 1ms 内可以完成很多次线程调度（一般情况 1ms 可以完成几十次线程调度），Go 发起 IO/syscall 的时候执行该 G 的 M 会阻塞然后被 OS 调度走，P 什么也不干，sysmon 最慢要 10-20ms 才能发现这个阻塞，说不定那时候阻塞已经结束了，这样宝贵的 P 资源就这么被阻塞的 M 浪费了。</p>
<h2 id="9-m-和-p-的数量问题">9. M 和 P 的数量问题</h2>
<p>P 默认 CPU 核心数。<br>
M 与 P 的数量没有绝对关系，一个 M 阻塞，P 就会去创建或者切换另一个 M，所以，即使 P 的默认数量是 1，也有可能会创建很多个 M 出来。</p>
<h2 id="10-gmp-调度过程中存在哪些阻塞">10. GMP 调度过程中存在哪些阻塞</h2>
<p>Sysmon 也叫监控线程，变动的周期性检查，好处：</p>
<ul>
<li>释放闲置超过 5 分钟的 span 物理内存；</li>
<li>如果超过 2 分钟没有垃圾回收，强制执行；</li>
<li>将长时间未处理的 netpoll 添加到全局队列；</li>
<li>向长时间运行的 G 任务发出抢占调度（超过 10ms 的 G，会进行 retake）；</li>
<li>收回因 syscall 长时间阻塞的 P。</li>
</ul>
<h2 id="11-三色标记原理">11. 三色标记原理</h2>
<p>我们首先看一张图，大概就会对三色标记法有一个大致的了解：<br>
原理：</p>
<ol>
<li>首先把所有的对象都放到白色的集合中。</li>
<li>从根节点开始遍历对象，遍历到的白色对象从白色集合中放到灰色集合中。</li>
<li>遍历灰色集合中的对象，把灰色对象引用的白色集合的对象放入到灰色集合中，同时把遍历过的灰色集合中的对象放到黑色的集合中。</li>
<li>循环步骤 3，直到灰色集合中没有对象。</li>
<li>步骤 4 结束后，白色集合中的对象就是不可达对象，也就是垃圾，进行回收。</li>
</ol>
<h2 id="12-写屏障">12. 写屏障</h2>
<p>Go 在进行三色标记的时候并没有 STW，也就是说，此时的对象还是可以进行修改。<br>
那么我们考虑一下，下面的情况：<br>
我们在进行三色标记中扫描灰色集合中，扫描到了对象 A，并标记了对象 A 的所有引用，这时候，开始扫描对象 D 的引用，而此时，另一个 goroutine 修改了 D-&gt;E 的引用。<br>
这样会不会导致 E 对象就扫描不到了，而被误认为是白色对象。写屏障就是为了解决这样的问题，引入写屏障后，在上述步骤后，E 会被认为是存活的，即使后面 E 被 A 对象抛弃，E 会被在下一轮的 GC 中进行回收，这一轮 GC 中是不会对对象 E 进行回收的。</p>
<h2 id="13-插入写屏障">13. 插入写屏障</h2>
<p>Go GC 在混合写屏障之前，一直是插入写屏障，由于栈赋值没有 hook 的原因，栈中没有启用写屏障，所以有 STW。<br>
Golang 的解决方法是：只是需要在结束时启动 STW 来重新扫描栈。这个自然就会导致整个进程的赋值器卡顿。</p>
<h2 id="14-删除写屏障">14. 删除写屏障</h2>
<p>Golang 没有这一步，Golang 的内存写屏障是由插入写屏障到混合写屏障过渡的。简单介绍一下，一个对象即使被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一轮 GC 中才被清理掉。</p>
<h2 id="15-混合写屏障">15. 混合写屏障</h2>
<ul>
<li>混合写屏障继承了插入写屏障的优点，起始无需 STW 打快照，直接并发扫描垃圾即可；</li>
<li>混合写屏障继承了删除写屏障的优点，赋值器是黑色赋值器，GC 期间，任何在栈上创建的新对象均为黑色。扫描过一次就不需要扫描了，这样就消除了插入写屏障时期最后 STW 的重新扫描栈；</li>
<li>混合写屏障扫描精度继承了删除写屏障，比插入写屏障更低，随着带来的是 GC 过程全程无 STW；</li>
<li>混合写屏障扫描栈虽然没有 STW，但是扫描某一个具体的栈的时候，还是要停止这个 goroutine 赋值器的工作（针对一个 goroutine 栈来说，是暂停扫的，要么全灰，要么全黑哈，原子状态切换）。</li>
</ul>
<h2 id="16-gc-触发时机">16. GC 触发时机</h2>
<p>有关 GC 详细内容可以查看笔者另一篇文章：<a href="https://bytetech.info/articles/7360889177946701876">GC 触发时机</a>。</p>
<ul>
<li><strong>主动触发</strong>：调用 <code>runtime.GC</code>；</li>
<li><strong>被动触发</strong>：使用系统监控，该触发条件由 <code>runtime.forcegcperiod</code> 变量控制，默认为 2 分钟。当超过两分钟没有产生任何 GC 时，强制触发 GC。使用步调（Pacing）算法，其核心思想是控制内存增长的比例。如 Go 的 GC 是一种比例 GC，下一次 GC 结束时的堆大小和上一次 GC 存活堆大小成比例。</li>
</ul>
<h2 id="17-go-gc-是怎么实现的">17. Go GC 是怎么实现的？</h2>
<p>Go 的 GC 回收有三次演进过程：</p>
<ul>
<li>Go V1.3 之前普通标记清除（mark and sweep）方法，整体过程需要启动 STW，效率极低。</li>
<li>Go V1.5 三色标记法，堆空间启动写屏障，栈空间不启动，全部扫描之后，需要重新扫描一次栈（需要 STW），效率普通。</li>
<li>Go V1.8 三色标记法，混合写屏障机制：栈空间不启动（全部标记成黑色），堆空间启用写屏障，整个过程不要 STW，效率高。</li>
</ul>
<p>Go1.3 之前的版本所谓标记清除是先启动 STW 暂停，然后执行标记，再执行数据回收，最后停止 STW。Go1.3 版本标记清除做了点优化，流程是：先启动 STW 暂停，然后执行标记，停止 STW，最后再执行数据回收。<br>
Go1.5 三色标记主要是插入屏障和删除屏障，写入屏障的流程：</p>
<ol>
<li>程序开始，全部标记为白色。</li>
<li>所有的对象放到白色集合。</li>
<li>遍历一次根节点，得到灰色节点。</li>
<li>遍历灰色节点，将可达的对象，从白色标记为灰色，遍历之后的灰色标记成黑色。</li>
<li>由于并发特性，此刻外界向在堆中的对象发生添加对象，以及在栈中的对象添加对象，在堆中的对象会触发插入屏障机制，栈中的对象不触发。</li>
<li>由于堆中对象插入屏障，则会把堆中黑色对象添加的白色对象改成灰色，栈中的黑色对象添加的白色对象依然是白色。</li>
<li>循环第 6 步，直到没有灰色节点。</li>
<li>在准备回收白色前，重新遍历扫描一次栈空间，加上 STW 暂停保护栈，防止外界干扰（有新的白色会被添加成黑色）在 STW 中，将栈中的对象一次三色标记，直到没有灰色。</li>
<li>停止 STW，清除白色。至于删除写屏障，则是遍历灰色节点的时候出现可达的节点被删除，这个时候触发删除写屏障，这个可达的被删除的节点也是灰色，等循环三色标记之后，直到没有灰色节点，然后清理白色，删除写屏障会造成一个对象即使被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一轮 GC 中被清理掉。</li>
</ol>
<p>Go V1.8 混合写屏障规则是：</p>
<ol>
<li>GC 开始将栈上的对象全部扫描并标记为黑色（之后不再进行第二次重复扫描，无需 STW）。</li>
<li>GC 期间，任何在栈上创建的新对象均为黑色。</li>
<li>被删除的对象标记为灰色。</li>
<li>被添加的对象标记为灰色。</li>
</ol>
<h2 id="18-go-语言中-gc-的流程是什么">18. Go 语言中 GC 的流程是什么？</h2>
<p>Go 1.14 版本以 STW 为界限，可以将 GC 划分为五个阶段：</p>
<ol>
<li><strong>GCMark</strong>：标记准备阶段，为并发标记做准备工作，启动写屏障；</li>
<li><strong>STWGCMark</strong>：扫描标记阶段，与赋值器并发执行，写屏障开启并发；</li>
<li><strong>GCMarkTermination</strong>：标记终止阶段，保证一个周期内标记任务完成，停止写屏障；</li>
<li><strong>GCoff</strong>：内存清扫阶段，将需要回收的内存归还到堆中，写屏障关闭；</li>
<li><strong>GCoff</strong>：内存归还阶段，将过多的内存归还给操作系统，写屏障关闭。</li>
</ol>
<h2 id="19-gc-如何调优">19. GC 如何调优</h2>
<p>通过 <code>go tool pprof</code> 和 <code>go tool trace</code> 等工具。</p>
<ul>
<li>控制内存分配的速度，限制 Goroutine 的数量，从而提高赋值器对 CPU 的利用率。</li>
<li>减少并复用内存，例如，使用 <code>sync.Pool</code> 来复用需要频繁创建临时对象，例如，提前分配足够的内存来降低多余的拷贝。</li>
<li>需要时，增大 <code>GOGC</code> 的值，降低 GC 的运行频率。</li>
</ul>
<h2 id="20-知道-golang-的内存逃逸吗什么情况下会发生内存逃逸">20. 知道 Golang 的内存逃逸吗？什么情况下会发生内存逃逸？</h2>
<ul>
<li>本该分配到栈上的变量，跑到了堆上，这就导致了内存逃逸。</li>
<li>栈是高地址到低地址，栈上的变量，函数结束后变量会跟着回收掉，不会有额外性能的开销。</li>
<li>变量从栈逃逸到堆上，如果要回收掉，需要进行 GC，那么 GC 一定会带来额外的性能开销。编程语言不断优化 GC 算法，主要目的都是为了减少 GC 带来的额外性能开销，变量一旦逃逸会导致性能开销变大。</li>
</ul>
<h3 id="内存逃逸的情况如下">内存逃逸的情况如下：</h3>
<ol>
<li>方法内返回局部变量指针。</li>
<li>向 channel 发送指针数据。</li>
<li>在闭包中引用包外的值。</li>
<li>在 slice 或 map 中存储指针。</li>
<li>切片（扩容后）长度太大。</li>
<li>在 interface 类型上调用方法。</li>
</ol>
<h2 id="21-谈谈内存泄漏什么情况下内存会泄漏怎么定位排查内存泄漏问题">21. 谈谈内存泄漏，什么情况下内存会泄漏？怎么定位排查内存泄漏问题？</h2>
<p>Go 中的内存泄漏一般都是 goroutine 泄漏，就是 goroutine 没有被关闭，或者没有添加超时控制，让 goroutine 一直处于阻塞状态，不能被 GC。<br>
内存泄漏有下面一些情况：</p>
<ul>
<li>如果 goroutine 在执行时被阻塞而无法退出，就会导致 goroutine 的内存泄漏，一个 goroutine 的最低栈大小为 2KB，在高并发的场景下，对内存的消耗也是非常恐怖的。</li>
<li>互斥锁未```markdown<br>
释放或者造成死锁会造成内存泄漏。</li>
<li><code>time.Ticker</code> 是每隔指定的时间就会向通道内写数据。作为循环触发器，必须调用 <code>stop</code> 方法才会停止，从而被 GC 掉，否则会一直占用内存空间。</li>
<li>字符串的截取引发临时性的内存泄漏：<pre><code class="language-go">func main() {
    var str0 = &quot;12345678901234567890&quot;
    str1 := str0[:10]
}
</code></pre>
</li>
<li>切片截取引起子切片内存泄漏：<pre><code class="language-go">func main() {
    var s0 = []int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}
    s1 := s0[:3]
}
</code></pre>
</li>
<li>函数数组传参引发内存泄漏：如果我们在函数传参的时候用到了数组传参，且这个数组够大（假设数组大小为 100 万，64 位机上消耗的内存约为 800w 字节，即 8MB 内存），或者该函数短时间内被调用 N 次，那么可想而知，会消耗大量内存，对性能产生极大的影响，如果短时间内分配大量内存，而又来不及 GC，那么就会产生临时性的内存泄漏，对于高并发场景相当可怕。</li>
</ul>
<h3 id="排查方式">排查方式：</h3>
<p>一般通过 <code>pprof</code> 是 Go 的性能分析工具，在程序运行过程中，可以记录程序的运行信息，可以是 CPU 使用情况、内存使用情况、goroutine 运行情况等。当需要性能调优或者定位 Bug 时，这些记录的信息是相当重要。</p>
<h2 id="22-channel-分配在栈上还是堆上哪些对象分配在堆上哪些对象分配在栈上">22. Channel 分配在栈上还是堆上？哪些对象分配在堆上，哪些对象分配在栈上？</h2>
<p>Channel 被设计用来实现协程间通信的组件，其作用域和生命周期不可能仅限于某个函数内部，所以 Golang 直接将其分配在堆上。准确地说，你并不需要知道。Golang 中的变量只要被引用就一直会存活，存储在堆上还是栈上由内部实现决定而和具体的语法没有关系。</p>
<p>知道变量的存储位置确实和效率编程有关系。如果可能，Golang 编译器会将函数的局部变量分配到函数栈帧（stack frame）上。然而，如果编译器不能确保变量在函数 return 之后不再被引用，编译器就会将变量分配到堆上。而且，如果一个局部变量非常大，那么它也应该被分配到堆上而不是栈上。</p>
<p>当前情况下，如果一个变量被取地址，那么它就有可能被分配到堆上，然而，还要对这些变量做逃逸分析。如果函数 return 之后，变量不再被引用，则将其分配到栈上。</p>
<h2 id="23-对已经关闭的-chan-进行读写会怎么样为什么">23. 对已经关闭的 chan 进行读写，会怎么样？为什么？</h2>
<ul>
<li>
<p><strong>读已经关闭的 chan</strong>：能一直读到东西，但是读到的内容根据通道内关闭前是否有元素而不同。</p>
<ul>
<li>如果 chan 关闭前，buffer 内有元素还未读，会正确读到 chan 内的值，且返回的第二个 bool 值（是否读成功）为 true。</li>
<li>如果 chan 关闭前，buffer 内有元素已经被读完，chan 内无值，接下来所有接收的值都会非阻塞直接成功，返回 channel 元素的零值，但是第二个 bool 值一直为 false。</li>
</ul>
</li>
<li>
<p><strong>写已经关闭的 chan</strong>：会 panic。</p>
</li>
</ul>
<h2 id="24-对未初始化的-chan-进行读写会怎样为什么">24. 对未初始化的 chan 进行读写，会怎样？为什么？</h2>
<ul>
<li>
<p><strong>对于写的情况</strong>：</p>
<ul>
<li>未初始化的 chan 此时是等于 nil，当它不能阻塞的情况下，直接返回 false，表示写 chan 失败。</li>
<li>当 chan 能阻塞的情况下，则直接阻塞 <code>gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2)</code>，然后调用 <code>throw(s string)</code> 抛出错误，其中 <code>waitReasonChanSendNilChan</code> 就是刚刚提到的报错 &quot;chan send (nil chan)&quot;。</li>
</ul>
</li>
<li>
<p><strong>对于读的情况</strong>：</p>
<ul>
<li>未初始化的 chan 此时是等于 nil，当它不能阻塞的情况下，直接返回 false，表示读 chan 失败。</li>
<li>当 chan 能阻塞的情况下，则直接阻塞 <code>gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2)</code>，然后调用 <code>throw(s string)</code> 抛出错误，其中 <code>waitReasonChanReceiveNilChan</code> 就是刚刚提到的报错 &quot;chan receive (nil chan)&quot;。</li>
</ul>
</li>
</ul>
<h2 id="25-说说-uintptr-和-unsafepointer-的区别">25. 说说 uintptr 和 unsafe.Pointer 的区别</h2>
<ul>
<li><code>unsafe.Pointer</code> 只是单纯的通用指针类型，用于转换不同类型指针，它不可以参与指针运算。</li>
<li>而 <code>uintptr</code> 是用于指针运算的，GC 不把 <code>uintptr</code> 当指针，也就是说 <code>uintptr</code> 无法持有对象，<code>uintptr</code> 类型的目标会被回收。</li>
<li><code>unsafe.Pointer</code> 可以和普通指针进行相互转换。</li>
<li><code>unsafe.Pointer</code> 可以和 <code>uintptr</code> 进行相互转换。</li>
</ul>
<h3 id="举例">举例：</h3>
<pre><code class="language-go">package main

import (
    &quot;fmt&quot;
    &quot;unsafe&quot;
)

type W struct {
    b int32
    c int64
}

func main() {
    var w *W = new(W)
    // 这时 w 的变量打印出来都是默认值 0，0
    fmt.Println(w.b, w.c)

    // 现在我们通过指针运算给 b 变量赋值为 10
    b := unsafe.Pointer(uintptr(unsafe.Pointer(w)) + unsafe.Offsetof(w.b))
    *((*int)(b)) = 10
    // 此时结果就变成了 10，0
    fmt.Println(w.b, w.c)
}
</code></pre>
<ul>
<li><code>uintptr(unsafe.Pointer(w))</code> 获取了 w 的指针起始值。</li>
<li><code>unsafe.Offsetof(w.b)</code> 获取 b 变量的偏移量。</li>
<li>两个相加就得到了 b 的地址值，将通用指针 <code>Pointer</code> 转换成具体指针 <code>((*int)(b))</code>，通过 <code>*</code> 符号取值，然后赋值。<code>*((*int)(b))</code> 相当于把 <code>(*int)(b)</code> 转换成 <code>int</code> 了，最后对变量重新赋值成 10，这样指针运算就完成了。</li>
</ul>
<h2 id="26-介绍一下大对象小对象为什么小对象多了会造成-gc-压力">26. 介绍一下大对象小对象，为什么小对象多了会造成 GC 压力？</h2>
<p>小于等于 32k 的对象就是小对象，其它都是大对象。一般小对象通过 <code>mspan</code> 分配内存；大对象则直接由 <code>mheap</code> 分配内存。通常小对象过多会导致 GC 三色法消耗过多的 CPU。优化思路是，减少对象分配。</p>
<ul>
<li><strong>小对象</strong>：如果申请小对象时，发现当前内存空间不存在空闲跨度时，将会需要调用 <code>nextFree</code> 方法获取新的可用的对象，可能会触发 GC 行为。</li>
<li><strong>大对象</strong>：如果申请大于 32k 以上的大对象时，可能会触发 GC 行为。</li>
</ul>
<h2 id="27-go-语言的栈空间管理是怎么样的">27. Go 语言的栈空间管理是怎么样的？</h2>
<p>Go 语言的运行环境（runtime）会在 goroutine 需要的时候动态地分配栈空间，而不是给每个 goroutine 分配固定大小的内存空间。这样就避免了需要程序员来决定栈的大小。</p>
<p>分块式的栈是最初 Go 语言组织栈的方式。当创建一个 goroutine 的时候，它会分配一个 8KB 的内存空间来给 goroutine 的栈使用。我们可能会考虑当这 8KB 的栈空间被用完的时候该怎么办？</p>
<p>为了处理这种情况，每个 Go 函数的开头都有一小段检测代码。这段代码会检查我们是否已经用完了分配的栈空间。如果是的话，它会调用 <code>morestack</code> 函数。<code>morestack</code> 函数分配一块新的内存作为栈空间，并且在这块栈空间的底部填入各种信息（包括之前的那块栈地址）。在分配了这块新的栈空间之后，它会重试刚才造成栈空间不足的函数。这个过程叫做栈分裂（stack split）。</p>
<p>在新分配的栈底部，还插入了一个叫做 <code>lessstack</code> 的函数指针。这个函数还没有被调用。这样设置是为了从刚才造成栈空间不足的那个函数返回时做准备的。当我们从那个函数返回时，它会跳转到 <code>lessstack</code>。<code>lessstack</code> 函数会查看在栈底部存放的数据结构里的信息，然后调整栈指针（stack pointer）。这样就完成了从新的栈块到老的栈块的跳转。接下来，新分配的这个块栈空间就可以被释放掉。</p>
<p>分块式的栈让我们能够按照需求来扩展和收缩栈的大小。Go 开发者不需要花精力去估计 goroutine 会用到多大的栈。创建一个新的 goroutine 的开销也不大。当 Go 开发者不知道栈会扩展到多少大时，它也能很好的处理这种情况。</p>
<p>这一直是之前 Go 语言管理栈的方法。但这个方法有一个问题。缩减栈空间是一个开销相对较大的操作。如果在一个循环里有栈分裂，那么它的开销就变得不可忽略了。一个函数会扩展，然后分裂栈。当它返回的时候又会释放之前分配的内存块。如果这些都发生在一个循环里的话，代价是相当大的。这就是所谓的热分裂问题（hot split problem）。它是 Go 语言开发者选择新的栈管理方法的主要原因。</p>
<p>新的方法叫做栈复制法（stack copying）。栈复制法一开始和分块式的栈很像。当 goroutine 运行并用完栈空间的时候，与之前的方法一样，栈溢出检查会被触发。但是，不像之前的方法那样分配一个新的内存块并链接到老的栈内存块，新的方法会分配一个两倍大的内存块并把老的内存块内容复制到新的内存块里。这样做意味着当栈缩减回之前大小时，我们不需要做任何事情。栈的缩减没有任何代价。而且，当栈再次扩展时，运行环境也不需要再做任何事。它可以重用之前分配的空间。</p>
<p>栈的复制听起来很容易，但实际操作并非那么简单。存储在栈上的变量的地址可能已经被使用到。也就是说程序使用到了一些指向栈的指针。当移动栈的时候，所有指向栈里内容的指针都会变得无效。然而，指向栈内容的指针自身也必定是保存在栈上的。这是为了保证内存安全的必要条件。否则一个程序就有可能访问一段已经无效的栈空间了。</p>
<p>因为垃圾回收的需要，我们必须知道栈的哪些部分是被用作指针了。当我们移动栈的时候，我们可以更新栈里的指针让它们指向新的地址。所有相关的指针都会被更新。我们使用了垃圾回收的信息来复制栈，但并不是任何使用栈的函数都有这些信息。因为很大一部分运行环境是用 C 语言写的，很多被调用的运行环境里的函数并没有指针的信息，所以也就不能够被复制了。当遇到这种情况时，我们只能退回到分块式的栈并支付相应的开销。</p>
<p>这也是为什么现在运行环境的开发者正在用 Go 语言不断优化栈管理，以提高性能和内存使用效率。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ES踩坑记录]]></title>
        <id>https://mzhtech.github.io/post/es-cai-keng-ji-lu/</id>
        <link href="https://mzhtech.github.io/post/es-cai-keng-ji-lu/">
        </link>
        <updated>2024-09-24T13:36:50.000Z</updated>
        <content type="html"><![CDATA[<h1 id="es简介">ES简介</h1>
<p>Elasticsearch，就是大名鼎鼎的搜索引擎，但搜索引擎不仅仅可以用来做百度那种的模糊搜索，对于性能的提升也十分强大。</p>
<h2 id="使用场景">使用场景</h2>
<p>以下场景可以考虑使用ES：</p>
<ol>
<li>模糊搜索，需要联想的模糊搜索</li>
<li>MySQL的关系模型无法支撑复杂的关系结构
<ol>
<li>由于查询需要，利用关系模型查询代价很大（疯狂联表）</li>
<li>数据的存储想走DDD的模型，但又不想因为DDD的模型导致搜索困难</li>
</ol>
</li>
<li>需要一个高并发的查询方式（大QPS）</li>
</ol>
<h2 id="如何理解es">如何理解ES？</h2>
<p>大家聊ES，都在聊倒排索引，但对于大多数业务来说，文本索引的场景，聊胜于无，所以不需要太看重和透彻了解倒排。</p>
<p>可以理解为一个自建的超多字段表，在这个表里开心搜索。</p>
<p>MySQL的模型是我们的基础业务模型，不是一种查询模型，而ES的模型多数情况下是紧贴业务场景的，业务场景需要字段，我直接加索引字段就好。</p>
<p>可以理解为一种自建的围绕在多个库外层的索引系统。</p>
<h3 id="如果你需要理解倒排">如果你需要理解倒排</h3>
<p>我借用几篇文章，可以参考这些前人的文章理解：</p>
<ul>
<li>维基百科的倒排索引说明的比较简洁清晰：<a href="https://zh.wikipedia.org/wiki/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95">倒排索引</a></li>
<li>Lucene简介：<a href="https://juejin.cn/post/6947984489960177677">Lucene简介</a></li>
</ul>
<p>简单理解：倒排索引主要用在模糊查询场景上，将一段文字利用分词算法提前分为N个单词，每个单词是一个存储单元，记录了这个单词在哪个地方出现过，频率是怎样的。</p>
<p>当进行查询时，对查询的内容也做分词算法，然后分割为单词进行搜索，即可获取一个相似度的概念（词频算法）。</p>
<h2 id="discussion为什么倒排索引叫倒排索引">Discussion：为什么倒排索引叫倒排索引？</h2>
<p>最简单的入门指南：</p>
<h2 id="架构">架构</h2>
<p>物理意义上：ES架构由以下三部分组成：</p>
<ul>
<li>集群（Cluster）</li>
<li>节点（Node）：按承担的角色划分为：Master节点、Client节点、Data节点等；</li>
<li>分片（Shard）：分为主分片(1)和副本分片(N)</li>
</ul>
<p>另外，逻辑意义上：索引的概念，一个集群上的索引，它可能具有多个分片，分布在多个节点上。</p>
<h2 id="利用mysql模型理解es">利用MySQL模型理解ES</h2>
<h3 id="索引-index">索引 (Index)</h3>
<p>类似MySQL中的DB+Table的组合，对SQL查询来说，Index就是一个Table，ES没有DB的概念了。在我司系统中，可以用SQL查询ES。</p>
<h3 id="映射-mapping">映射 (Mapping)</h3>
<p>描述Table的结构，示例：</p>
<pre><code class="language-json">{
  &quot;dynamic&quot;: &quot;false&quot;, // 是否使用动态字段
  &quot;properties&quot;: {
    &quot;channel_type&quot;: {
      &quot;type&quot;: &quot;integer&quot;
    },
    &quot;date&quot;: {
      &quot;index&quot;: false, // 表示不建立索引
      &quot;type&quot;: &quot;integer&quot;
    },
    &quot;encrypted_user_id&quot;: {
      &quot;index&quot;: false,
      &quot;type&quot;: &quot;long&quot;
    },
    &quot;msg_id&quot;: {
      &quot;index&quot;: false,
      &quot;type&quot;: &quot;keyword&quot;
    },
    &quot;sent_time&quot;: {
      &quot;index&quot;: false,
      &quot;type&quot;: &quot;integer&quot;
    },
    &quot;task_id&quot;: {
      &quot;type&quot;: &quot;long&quot;
    }
  }
}
</code></pre>
<h3 id="文档-document">文档 (Document)</h3>
<p>数据库的每一行数据，结构由Mapping规定。文档不需要有规定的全部字段，但同名字段的类型必须是相同的（提前规定或动态字段时，第一个数据决定）。</p>
<h3 id="es数据字段类型">ES数据字段类型</h3>
<p>亲测，类型定了以后，是不能随便改的，如数字与字符之间不能互相改，但可以扩大。</p>
<table>
<thead>
<tr>
<th>字段类型</th>
<th>ElasticSearch类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>string,varchar</td>
<td>keyword</td>
<td>不可标记字段，类似ID的概念</td>
</tr>
<tr>
<td>string,varchar</td>
<td>text</td>
<td>要标记化的字段，比如商品名</td>
</tr>
<tr>
<td>integer</td>
<td>integer</td>
<td>32位整数</td>
</tr>
<tr>
<td>long</td>
<td>long</td>
<td>64位整数</td>
</tr>
<tr>
<td>float</td>
<td>float</td>
<td>32位浮点数</td>
</tr>
<tr>
<td>double</td>
<td>double</td>
<td>64位浮点数</td>
</tr>
<tr>
<td>boolean</td>
<td>boolean</td>
<td>布尔值</td>
</tr>
<tr>
<td>date/datetime</td>
<td>date</td>
<td>日期值</td>
</tr>
<tr>
<td>bytes/binary</td>
<td>binary</td>
<td>二进制，文件或字节流</td>
</tr>
</tbody>
</table>
<h3 id="自动创建映射">自动创建映射</h3>
<p>先创建一个索引，打开动态索引：</p>
<pre><code class="language-json">{
  &quot;dynamic&quot;: &quot;true&quot;,
  &quot;properties&quot;: {}
}
</code></pre>
<p>然后填一个数据进去，此时ES动态生成了mapping。如果我们加入新数据，数据类型不同，则会出现报错。</p>
<h3 id="显示映射创建">显示映射创建</h3>
<p>自动创建的映射可能对性能带来影响，比如文本字段本身是keyword类型，却自动用了text开了倒排索引。</p>
<pre><code class="language-json">{
  &quot;dynamic&quot;: &quot;false&quot;,
  &quot;properties&quot;: {
    &quot;channel_type&quot;: {
      &quot;type&quot;: &quot;integer&quot;
    },
    &quot;date&quot;: {
      &quot;index&quot;: false,
      &quot;type&quot;: &quot;integer&quot;
    },
    &quot;encrypted_user_id&quot;: {
      &quot;index&quot;: false,
      &quot;type&quot;: &quot;long&quot;
    },
    &quot;msg_id&quot;: {
      &quot;index&quot;: false,
      &quot;type&quot;: &quot;keyword&quot;
    },
    &quot;sent_time&quot;: {
      &quot;index&quot;: false,
      &quot;type&quot;: &quot;integer&quot;
    },
    &quot;task_id&quot;: {
      &quot;type&quot;: &quot;long&quot;
    }
  }
}
</code></pre>
<h3 id="数组和对象json">数组和对象（JSON）</h3>
<p>对于数组，ES每个字段都自动作为数组进行管理，不需要特殊声明。</p>
<p>对于对象类型，示例：</p>
<pre><code class="language-json">{
  &quot;properties&quot;: {
    &quot;tag&quot;: {
      &quot;type&quot;: &quot;integer&quot;
    },
    &quot;data&quot;: {
      &quot;type&quot;: &quot;object&quot;,
      &quot;properties&quot;: {
          &quot;name&quot;: {&quot;type&quot;: &quot;text&quot;}
      }
    }
  }
}
</code></pre>
<h3 id="查询入门">查询入门</h3>
<p>Domain Specific Language：领域特定语言</p>
<p>Elasticsearch基于JSON提供完整的查询DSL来定义查询。</p>
<p>一个查询可由两部分字句构成：</p>
<ul>
<li><strong>Leaf query clauses</strong>：在指定的字段上查询指定的值，如：match, term or range queries。</li>
<li><strong>Compound query clauses</strong>：以逻辑方式组合多个叶子、复合查询为一个查询。</li>
</ul>
<h3 id="基础搜索模式">基础搜索模式</h3>
<h4 id="match-all-查询">Match ALL 查询</h4>
<p>最简单的查询，它匹配所有文档，给它们一个_score 1.0。</p>
<pre><code class="language-json">GET /_search
{
    &quot;query&quot;: {
        &quot;match_all&quot;: {}
    }
}
</code></pre>
<h4 id="match-none-查询">Match None 查询</h4>
<p>这是 match_all 查询相反，它不匹配任何文档。</p>
<pre><code class="language-json">GET /_search
{
    &quot;query&quot;: {
        &quot;match_none&quot;: {}
    }
}
</code></pre>
<h4 id="全文查询">全文查询</h4>
<p>用于对分词的字段进行搜索。会用查询字段的分词器对查询的文本进行分词生成查询。可用于短语查询、模糊查询、前缀查询、临近查询等查询场景。</p>
<h5 id="match-query">match query</h5>
<p>全文查询的标准查询，它可以对一个字段进行模糊、短语查询。</p>
<pre><code class="language-json">GET /_search
{
    &quot;query&quot;: {
        &quot;match&quot;: {
            &quot;message&quot;: &quot;this is a test&quot;  // message是字段名
        }
    }
}
</code></pre>
<h5 id="match-phrase-query">match phrase query</h5>
<p>用于对一个字段进行短语查询。</p>
<pre><code class="language-json">GET ftq/_search
{
  &quot;query&quot;: {
    &quot;match_phrase&quot;: {
      &quot;title&quot;: &quot;lucene solr&quot;
    }
  }
}
</code></pre>
<h5 id="multi-match-query">multi match query</h5>
<p>如果你需要在多个字段上进行文本搜索，可用multi_match。</p>
<pre><code class="language-json">GET ftq/_search
{
  &quot;query&quot;: {
    &quot;multi_match&quot;: {
      &quot;query&quot;: &quot;lucene java&quot;, 
      &quot;fields&quot;: [&quot;title&quot;, &quot;content&quot;] 
    }
  }
}
</code></pre>
<h2 id="复合查询">复合查询</h2>
<h3 id="bool-query">bool query</h3>
<p>Bool 查询用bool操作来组合多个查询字句为一个查询。</p>
<pre><code class="language-json">POST /_search
{
  &quot;query&quot;: {
    &quot;bool&quot;: {
      &quot;must&quot;: {
        &quot;term&quot;: { &quot;user&quot;: &quot;kimchy&quot; }
      },
      &quot;filter&quot;: {
        &quot;term&quot;: { &quot;tag&quot;: &quot;tech&quot; }
      },
      &quot;must_not&quot;: {
        &quot;range&quot;: {
          &quot;age&quot;: { &quot;gte&quot;: 10, &quot;lte&quot;: 20 }
        }
      },
      &quot;should&quot;: [
        { &quot;term&quot;: { &quot;tag&quot;: &quot;wow&quot; } },
        { &quot;term&quot;: { &quot;tag&quot;: &quot;elasticsearch&quot; } }
      ],
      &quot;minimum_should_match&quot;: 1,
      &quot;boost&quot;: 1.0
    }
  }
}
</code></pre>
<h2 id="分页搜索">分页搜索</h2>
<h3 id="普通分页">普通分页</h3>
<pre><code class="language-json">GET /_search
{
    &quot;from&quot;: 0,
    &quot;size&quot;: 10,
    &quot;query&quot;: {
        &quot;term&quot;: { &quot;user&quot;: &quot;kimchy&quot; }
    }
}
</code></pre>
<p>注意：搜索请求耗用的堆内存和时间与 <code>from + size</code> 大小成正比。分页越深耗用越大，为了不因分页导致OOM或严重影响性能，ES中规定 <code>from + size</code> 不能大于索引设置参数 <code>index.max_result_window</code> 的值，默认值为 10000。</p>
<h3 id="search_after">search_after</h3>
<p>需要配合Sort使用，在指定文档后面取文档，可用于深度分页。</p>
<p>首次查询第一页：</p>
<pre><code class="language-json">GET twitter/_search
{
    &quot;size&quot;: 10,
    &quot;query&quot;: {
        &quot;match&quot;: {
            &quot;title&quot;: &quot;elasticsearch&quot;
        }
    },
    &quot;sort&quot;: [
        {&quot;date&quot;: &quot;asc&quot;},
        {&quot;_id&quot;: &quot;desc&quot;}
    ]
}
</code></pre>
<p>后续的查询：</p>
<pre><code class="language-json">GET twitter/_search
{
    &quot;size&quot;: 10,
    &quot;query&quot;: {
        &quot;match&quot;: {
            &quot;title&quot;: &quot;elasticsearch&quot;
        }
    },
    &quot;search_after&quot;: [1463538857, &quot;654323&quot;],
    &quot;sort&quot;: [
        {&quot;date&quot;: &quot;asc&quot;},
        {&quot;_id&quot;: &quot;desc&quot;}
    ]
}
</code></pre>
<h2 id="高阶操作与深入">高阶操作与深入</h2>
<h3 id="三大查询场景">三大查询场景</h3>
<ul>
<li>Search</li>
<li>Scroll</li>
<li>Search After</li>
</ul>
<h3 id="es深分页问题">ES深分页问题</h3>
<p>ES为了保证服务的稳定性，将深分页设置为1W，当普通的分页请求超过1W的深度后，ES将会报错并拒绝请求。</p>
<h3 id="为什么要有深分页保护">为什么要有深分页保护？</h3>
<p>ES的这种方式提供了分页的功能，同时，也有相应的限制。</p>
<p>举个例子，一个索引，有1亿数据，分10个shards，然后，一个搜索请求，<code>from=1,000,000</code>，<code>size=100</code>，这时候，会带来严重的性能问题。</p>
<h3 id="scroll">Scroll</h3>
<p>支持深分页，需要额外改造API。</p>
<p>官网描述：scroll 查询可以用来对 Elasticsearch 有效地执行大批量的文档查询，而又不用付出深度分页那种代价。</p>
<h3 id="search-after">Search After</h3>
<p>支持深分页，默认在search中加入order即可开启，不需要额外改造。</p>
<pre><code class="language-json">GET twitter/_search
{
    &quot;size&quot;: 10,
    &quot;query&quot;: {
        &quot;match&quot;: {
            &quot;title&quot;: &quot;elasticsearch&quot;
        }
    },
    &quot;sort&quot;: [
        {&quot;date&quot;: &quot;asc&quot;},
        {&quot;tie_breaker_id&quot;: &quot;asc&quot;}
    ]
}
</code></pre>
<h2 id="结语">结语</h2>
<p>Elasticsearch是一个强大的搜索引擎，适用于多种场景。通过合理的设计和使用，可以大大提升系统的性能和用户体验。希望本篇文章能帮助你更好地理解和使用ES。</p>
]]></content>
    </entry>
</feed>